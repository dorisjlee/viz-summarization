%!TEX root = main.tex
\section{Related Work}

Our work draws from, and improves upon, past research in multidimensional data exploration, fallacies in visual analytics, decision tree visualization, and visualization storytelling.

\subsection{Guided Exploration of Multidimensional Data}
Given a dataset, tools such as Tableau support automatic generation of visualizations based on perceptual graphical presentation rules~\cite{Mackinlay2007,Wongsuphasawat2016}. A more recent body of work automatically selects visualizations based on statistical measures, such as scagnostics and deviation. Given a scatterplot, Anand et al. \cite{Anand2015} applies randomized permutation tests to select partitioning variables that reveals interesting small multiples using scagnostics. Given a bar chart, Vartak et al. \cite{Vartak2015} finds other interesting bar charts that deviate form the input chart using a deviation-based measure. Our work extends the deviation-based measure to formulate user expectation. However, unlike existing works, we concentrate on informativeness, which enables our system to avoid drill-down fallacies.
%\cite{Elmqvist2008Rolling} presents an interactive tool to explore multidimensional data using a matrix of scatterplots that shows the relationship between all pairs of attributes.

\subsection{Preventing Biases and Statistical Fallacies}
Visualizations are powerful representations for discovering trends and patterns in a dataset; however, cognitive biases and statistical fallacies could mislead analysts' interpretation of those patterns~\cite{Alipourfard2018WSDM,Wall2017,Zgraggen2018CHI}. Wall et al.~\cite{Wall2017} presents six metrics to systematically detect and quantify bias from user interactions in visual analytic systems. These metrics are based on coverage and distribution, which focus on the assessment of the process by which users sample the data space. Alipourfard et al.~\cite{Alipourfard2018WSDM} presents a statistical method to automatically identify Simpson's paradox by comparing statistical trends in the aggregate data to those in the disaggregated subgroups. Zgraggen et al.~\cite{Zgraggen2018CHI} presents a method to detect the presence of the multiple comparisons problem in visual analysis. In this paper, we concentrate on a novel type of fallacy during drill-down exploration that has not been addressed by past work. %drill-down fallacy, a fallacy that has not been addressed before in visual analytics literature.

\subsection{Decision Tree Visualization}
The popularity of decision trees in a variety of classification tasks have led to the development of visualizations that make these models more interpretable~\cite{Ankerst1999,Hermann2017,Terence2018}. These visualizations often contain a visual representation of the rules as paths connecting the decision nodes, illustrating the proportion of sample along different paths, as well as statistics regarding the prediction accuracy at every node. Though our dashboards visually look similar to decision trees, the underlying objectives are different for the two methods. During tree construction, a decision tree algorithm aims to improve the classification accuracy of a target variable, typically by minimizing the entropy of distribution from parent node to child node~\cite{Quinlan1986}. In contrast, our method aims to deliver informative insights, by maximizing the informative deviation between parent and child nodes. Consequently, the generated outcomes are different for the two methods---a decision tree well explains the general rules (e.g., if stop duration is more than 30 minutes, the driver has 60\% probability of being arrested), whereas our method well explains the exceptions (e.g., if a stop duration is more than 30 minutes and the driver's race is Asian, the probability of arrest goes down to 35\%). Note that the general rule is useful for predicting the stop outcome for an unlabeled test datapoint (classification), whereas the exception is useful for realizing when the general rule no longer holds (insight). The latter insight may not be discovered by a decision tree as it does not directly improve classification accuracy. Another key difference between the two methods is \emph{coverage}---a decision tree covers the entire dataset (consistent with its classification goal), whereas our method highlights only the interesting regions of a dataset (consistent with its insight goal).

%While both methods are useful in understanding the distributions in different regions of data, and further in model interpretability. In particular, decision trees have been very successful in learning where and how a model works; our method could be useful in understanding where it might break.

\subsection{Storytelling with Visualization Sequences}
Visualizations are often arranged in a sequence to narrate a data-driven story. Existing work on visualization sequences and storytelling has studied the structures of narrative visualizations~\cite{Hullman2017,Segel2010}, effects of augmenting exploratory information visualizations with narration~\cite{Boy2015} and, more recently, ways to automate the creation of visualization sequences~\cite{Hullman2013,Kim2017}. Most of these work have adopted a linear layout (motivated by slidedecks) to present the visualization sequences. Hullman et al.~\cite{Hullman2017} found that most people prefer visualization sequences structured hierarchically based on shared data properties such as levels of aggregation. Kim et al.~\cite{Kim2017} modeled relationships between charts by empirically estimating transition (edge) cost between moving from one visualization (node) to another. They found that participants preferred ``\textit{starting from the entire data and introducing increasing levels of summarization}''. Our work is the first to automatically organize visualizations in a hierarchical layout for summarizing data distributions across the space of data subsets.

%Both \cite{Hullman2013,Kim2017} use a graph model to formalize the visualization design space.
%In addition, we present a novel problem formulation that recommends a connected visualization sequence in a hierarchical layout summarizing the space of data subsets.

% \iffalse
% \section{Related Works}
% \npar \stitle{Storytelling with visualization sequences:}
% Visualizations are often arranged in sequence to narrate a data story. Existing work on visualization sequences and storytelling have studied the structures of narrative visualizations\cite{Segel2010,Hullman2017}, effects of augmenting exploratory information visualizations with narration\cite{Boy2015} and, more recently, ways to automate the creation of visualization sequences\cite{Hullman2013,Kim2017}. Most of these work have adopted a linear layout (motivated by slidedecks) to present the visualization sequences. Hullman et al. \cite{Hullman2017} found that most people prefer visualization sequences structured hierarchically based on shared data properties such as levels of aggregation. %Both \cite{Hullman2013,Kim2017} use a graph model to formalize the visualization design space.
% Kim et al. \cite{Kim2017} models relationships between charts by empirically estimating transition (edge) cost between moving from one visualization (node) to another. They find that participants preferred ``\textit{starting from the entire data and introducing increasing levels of summarization}''. Our work is the first to automatically sequence visualizations in a hierarchical layout for summarizing the space of data subsets. %In addition, we present a novel problem formulation that recommends a connected visualization sequence in a hierarchical layout summarizing the space of data subsets.

% \subsection{Visualization recommendation}
% \par%Despite the large body of work that recommends informative visualizations given pre-selected data attributes and aggregations, the data selection problem is a more important problem in exploratory data analysis, since the analysts have to figure out which groups of data attributes would be of interest in order avoid manual exploration of the data.
% Visualization recommendation systems select appropriate visualizations to show based on an objective function. The metrics considered by these systems can largely be divided into two categories: perceptual or data-driven. The first type of recommendation system selects visualizations based on its visual effectiveness and expressiveness~\cite{Wongsuphasawat2016,Mackinlay2007}. Our work is more related to the latter category of systems which uses statistical measures computed based on the underlying data subset, such as cognostics or deviation. Anand et al. \cite{Anand2015} used randomized permutation tests to automatically select partitioning variables to display visualizations exhibiting patterns that are different from the input visualization as determined by its cognostic score. Vartak et al. \cite{Vartak2015} finds interesting visualizations by a deviation-based measure between the user's query view and reference view, given a query of interest. While both existing systems require the analyst to input a visualization of interest as a query, our paper extends the deviation-based idea to establish user's expectation using informative parent enabling \system to traverse the visualization lattice in search of a connected, maximally informative and interesting story without the need for an input query.  %Wongsuphasawat et al. \cite{Wongsuphasawat2016} presents a mixed-initiative system where the users direct the variables of interest and the system suggests other variables that may be potentially interesting to the user. Since this is a mixed-initiative system rather than an automatic recommendation engine, the system only ``looks ahead" one variable at a time. Their goal is to promote breadth-oriented data exploration rather than helping users find interesting stories or visualizations.

% %- the issue of surprisingness metric and ---- have been examined before for viz, but none have looked at data subset lattice specifically for viz

% \subsection{Data Exploration of OLAP Data Cubes} %\dor{This may be a bit long and need to be cut, I didn't include related works on surprisingness metrics (e.g. Bayesian Cognition paper, Surprise Map ,etc.). Can add if necessary.}
% The challenge of manual, unguided search in online analytical processing (OLAP) applications have been well studied in the context of data cube exploration by Sarawagi et al. ~\cite{Sarawagi1999,Sarawagi2000,Sarawagi1998}. To address this challenge, they simplify the search by identifying ``interesting'' regions of a data cube. These techniques includes precomputed statistics accounting for the surprisingness attributed to neighboring paths to cell and amount of deviation from constrained maximum entropy-based expectations. While these interesting sub-cubes correspond to finding filter combinations for constructing the aggregate visualization in \system, our lattice search space enforces fixed x, y and aggregation as well as connectedness during traversal to discover more interpretable stories.

% %Sarawagi et al.\cite{Sarawagi1998} introduced the problem that manual, unguided search for seeking interesting patterns in a datacube is inefficient and requires large numbers of online analytical processing (OLAP) operations, such as roll-up, drill-down, slicing, and dicing. They proposed a discovery-driven approach to data exploration to simplify the search for \textit{exceptions} in the data, based on precomputed statistics regarding how surprising a data cube cell is, relative to neighboring cells at the same level of aggregation, at levels of aggregation below the cell, and along the drill-down path. Sarawagi \cite{Sarawagi1999} presents an OLAP operator that summarizes the reasons for variation in a data view, by computing the information theoretic distance between the immediate parent and its child nodes.
% % \par While Sarawagi et al. \cite{Sarawagi1998} takes a more data-driven approach of finding exceptions intrinsic to a given datacube, Sarawagi \cite{Sarawagi2000} envisions a more user-centric application where the comparisons are based only on parents of seen visualization. The user's expectation regarding an unseen visualization is based on the maximum entropy principle where the relationships between the attributes should be maximally uniform across all dimensions, while being consistent with constraints from seen visualizations. The visualization that deviates the most from the user expectation is regarded as an ``interesting" visualization. They take an iterative approach to find the unique solution for the expected values for each attribute from the constrained maximum entropy problem and employ several optimization strategies (reusing computed values, sharing storage of contiguous regions, pruning constraints that subsumes one another or with little influence). Our coverage-based models improve on the iterative approach in providing a tighter constraint to the variable regions of the bars.
% \fi
