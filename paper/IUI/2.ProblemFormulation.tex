%!TEX root = main.tex
\section{Towards Informative Exploration}
In this section, we first describe how analysts manually explore the space of data subsets using drill-downs. We then introduce the three design principles aimed at addressing the current challenges of manual exploration, and automatically guide analysts to the key informative insights. 
\subsection{Manual Exploration via Drill-Downs}
During visual data exploration, an analyst may need to explore different subsets of the data, which form a combinatorial \emph{lattice}. Figure 1 shows a partial lattice for the 2016 US election polls. The lattice contains the overall visualization with no filter at the first level, all visualizations with a single filter at the second level, all visualizations with two filters at third level, and so on. Analysts explore such a combinatorial lattice from top to bottom, by generating and examining visualizations with increasing levels of aggregation. In particular, analysts perform drill-downs to access data subsets at lower levels by adding one filter at a time, and for each such data subset visualize their metrics of interest. Further, as analysts perform drill-downs, they use the most recent visualization in the drill-down path (known as the `parent') as a reference to establish what they expect to see in the new visualization (known as the `child'). For example in Figure~\ref{fig:elections_example}, the visualizations \texttt{Female} and \texttt{Black} are the \emph{parents} of the \texttt{Black Female} visualization, explored along the purple and orange path respectively.
\par As exemplified by the purple path in Figure~\ref{fig:elections_example}, during drill-downs analysts may be misguided by improper references that exhibits high deviation locally, in particular when other potential parents (i.e., parents not explored in the drill-down path) that could explain the more general phenomenon are overlooked. We refer to this misinterpretation as the \emph{drill-down fallacy}, since the fallacy arises from the inductive nature of the drill-down operation. 
\subsection{Three Elements of Informative Exploration}
Our goal is to enable users to discover the key informative insights in a dataset avoiding drill-down fallacies. We argue in favor of three essential principles for finding such insights---namely the three S's: safety, saliency, and summarization. We adopt these principles to develop a visual exploration tool that automatically selects visualizations that collectively convey the key informative insights of a multidimensional dataset.
\subsubsection{Safety}
To prevent the drill-down fallacy, we concentrate on \emph{safety}---using informative references for discovering insights. We identify informative references in a drill-down context by modeling the \emph{informativeness} of an observed parent in characterizing the child visualization. An observed parent is \emph{informative} if its data distribution closely follows the child visualization's data distribution, since the parent serves as a proper reference that helps analysts form an accurate mental picture of what to expect from the child visualization. Specifically, we formulate the informativeness of an observed parent $V_i^j$ for a visualization $V_i$ as the similarity between their data distributions measured using a distance function $D(V_i, V_i^j)$. The most informative parents $V_i^*$ for visualization $V_i$ are the ones whose data distributions are most similar to $V_i$.
\begin{equation}
    V_i^*=\underset{V_i^j}{argmin}\ D(V_i, V_i^j)
\end{equation}
We regard a visualization as informative if its distance falls within a user-defined threshold $\theta\%$ close to its most informative parent:
\begin{equation}
    V_i^{*, \theta} = \{V_i^j : \frac{D(V_i, V_i^*)}{D(V_i, V_i^j)} \geq \theta\}
\end{equation}
For example in Figure~\ref{fig:elections_example}, while both visualization \texttt{Black} and \texttt{Female} visualizations are considered parents of the \texttt{Black Female} visualization, only the \texttt{Black} visualization is considered an informative parent of the \texttt{Black Female} population, for any values of $\theta \geq 11\%$ via the Euclidean distance metric. To ensure the informativeness of our dashboards, we selected a more stringent \theta as 90\%  for the dashboards generated for our user study experiments. Note that our proposed system can work with other common distance metrics such as Kullback-Leibler Divergence and Earth Mover's distance~\cite{Vartak2015}. Without loss of generality, we chose to use Euclidean distance metric for the remainder of our paper.
\subsubsection{Saliency}
To discover insights, we emphasize \emph{saliency}---identifying interesting visualizations that convey new information. In general, a visualization is deemed to be interesting if its underlying data distribution differs from that of its parents, and thus offers new information or unexpected insights. The notion of such interestingness have been explored in past work~\cite{Vartak2015,Correll2016,Itti2009}, particularly through the usage of distance-based metrics. However, unlike past work, we concentrate on \emph{informative interestingness}, where the goal is to identify interesting visualizations in presence of informative references. Specifically, to model the interestingness of an visualization $V_i$ in the context of its \emph{informative} parent $V_i^j$, we characterize the deviation between their data distributions using $D(V_i, V_i^j)$. \agp{describe how this is a minmax objective.} Further, to address the effect of subpopulation size, we multiply the distance $D(V_i, V_i^j)$ between an informative parent $V_i^j$ and a child visualization $V_i$ by the ratio of their sizes  $U(V_i, V_i^j) = \frac{|V_i|}{|V_i^{j}|} \cdot D(V_i, V_i^j)$.
\subsubsection{Summarization}
To succinctly convey insights, we concentrate on \emph{summarization}---identifying a group of visualizations that collectively contain informative insights. Since our aim is to identify a unified narrative, instead of discrete insights, we enforce that any selected visualization must have its proper, informative parent be present in the dashboard. Specifically, we identify a set of $k$ connected visualizations that collectively maximize the proposed utility $U(V_i, V_i^j)$, and thus succinctly convey informative insights, more formally stated as follows:

\par \textsc{Problem.} \textit{Given user-provided X, Y attributes and aggregation function G, a lattice $\mathcal{L}$ consisting of visualizations $V_i$ for all possible filter $F_i$ that could be constructed from dataset D:} 
\\ \texttt{$V_i$ = SELECT X, G(Y) FROM D WHERE $F_i$ GROUP BY X}
\\ \textit{find k visualizations from $\mathcal{L}$ to include in dashboard $\mathcal{S}$, such that the total utility $\sum_{V\in \mathcal{L}} U(V_i, V_i^j)$ as defined above is maximized, while enforcing that all $V\in \mathcal{S}$ is connected.}

This problem of finding a connected subgraph in the lattice that has the maximum combined edge utility is known as the \emph{maximum-weight connected subgraph problem}~\cite{ErnstAlthaus2009} and is known to be NP-Complete~\cite{Parameswaran2010}. We design several approximate algorithms to solve this problem efficiently. 