%!TEX root = main.tex
\section{Related Work\label{sec:related}}
Our work draws from, and improves upon, past research in multidimensional data exploration and fallacies in visual analytics. \change{Other less-relevant past work on decision tree visualization and visualization storytelling is included as reference in the technical report.}
\subsection{Guided Exploration of Multidimensional Data}
Given a dataset, tools such as Tableau support automatic generation of visualizations based on perceptual graphical presentation rules~\cite{Mackinlay2007,Wongsuphasawat2016}. A more recent body of work automatically selects visualizations based on statistical measures, such as scagnostics and deviation. Given a scatterplot, Anand et al. \cite{Anand2015} applies randomized permutation tests to select partitioning variables that reveals interesting small multiples using scagnostics. Given a bar chart, Vartak et al. \cite{Vartak2015} finds other interesting bar charts that deviate from the input chart using a deviation-based measure. Our work extends the deviation-based measure to formulate user expectation. However, unlike existing works, we concentrate on informativeness, which enables our system to avoid drill-down fallacies.
%\cite{Elmqvist2008Rolling} presents an interactive tool to explore multidimensional data using a matrix of scatterplots that shows the relationship between all pairs of attributes.
% \dor{add smart drill-down~\cite{Joglekar2015}}
\subsection{Preventing Biases and Statistical Fallacies}
Visualizations are powerful representations for discovering trends and patterns in a dataset; however, cognitive biases and statistical fallacies could mislead analysts' interpretation of those patterns~\cite{Alipourfard2018WSDM,Wall2017,Zgraggen2018CHI,Armstrong2014}. Wall et al.~\cite{Wall2017} presents six metrics to systematically detect and quantify bias from user interactions in visual analytics. These metrics are based on coverage and distribution, which focus on the assessment of the process by which users sample the data space. Alipourfard et al.~\cite{Alipourfard2018WSDM} presents a statistical method to automatically identify Simpson's paradox by comparing statistical trends in the aggregate data to those in the disaggregated subgroups. Zgraggen et al.~\cite{Zgraggen2018CHI} presents a method to detect the presence of the multiple comparisons problem in visual analysis. In this paper, we concentrate on a novel type of fallacy during drill-down exploration that has not been addressed by past work. %drill-down fallacy, a fallacy that has not been addressed before in visual analytics literature.
\tr{
  \subsection{Decision Tree Visualization}
  The popularity of decision trees in a variety of classification tasks have led to the development of visualizations that make these models more interpretable~\cite{Ankerst1999,Hermann2017,Terence2018}. These visualizations often contain a visual representation of the rules as paths connecting the decision nodes, illustrating the proportion of sample along different paths, as well as statistics regarding the prediction accuracy at every node. Though our dashboards visually look similar to decision trees, the underlying objectives are different for the two methods. During tree construction, a decision tree algorithm aims to improve the classification accuracy of a target variable, typically by minimizing the entropy of distribution from parent node to child node~\cite{Quinlan1986}. In contrast, our method aims to deliver informative insights, by maximizing the informative deviation between parent and child nodes. Consequently, the generated outcomes are different for the two methods---a decision tree well explains the general rules (e.g., if stop duration is more than 30 minutes, the driver has 60\% probability of being arrested), whereas our method well explains the exceptions (e.g., if a stop duration is more than 30 minutes and the driver's race is Asian, the probability of arrest goes down to 35\%). Note that the general rule is useful for predicting the stop outcome for an unlabeled test datapoint (classification), whereas the exception is useful for realizing when the general rule no longer holds (insight). The latter insight may not be discovered by a decision tree as it does not directly improve classification accuracy. Another key difference between the two methods is \emph{coverage}---a decision tree covers the entire dataset (consistent with its classification goal), whereas our method highlights only the interesting regions of a dataset (consistent with its insight goal).

  \subsection{Storytelling with Visualization Sequences}
  Visualizations are often arranged in a sequence to narrate a data-driven story. Existing work on visualization sequences and storytelling has studied the structures of narrative visualizations~\cite{Hullman2017,Segel2010}, effects of augmenting exploratory information visualizations with narration~\cite{Boy2015} and, more recently, ways to automate the creation of visualization sequences~\cite{Hullman2013,Kim2017}. Most of these work have adopted a linear layout (motivated by slidedecks) to present the visualization sequences. Hullman et al.~\cite{Hullman2017} found that most people prefer visualization sequences structured hierarchically based on shared data properties such as levels of aggregation. Kim et al.~\cite{Kim2017} modeled relationships between charts by empirically estimating transition (edge) cost between moving from one visualization (node) to another. They found that participants preferred ``\textit{starting from the entire data and introducing increasing levels of summarization}''. Our work is the first to automatically organize visualizations in a hierarchical layout for summarizing data distributions across the space of data subsets.
}
