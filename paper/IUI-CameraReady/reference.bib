% Visual exploration of multidimensional data

@article{Stolte2002Polaris,
  title={Polaris: A system for query, analysis, and visualization of multidimensional relational databases},
  author={Stolte, Chris and Tang, Diane and Hanrahan, Pat},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={8},
  number={1},
  pages={52--65},
  year={2002},
  publisher={IEEE}
}

@article{Elmqvist2008Rolling,
  title={Rolling the dice: Multidimensional visual exploration using scatterplot matrix navigation},
  author={Elmqvist, Niklas and Dragicevic, Pierre and Fekete, Jean-Daniel},
  journal={IEEE transactions on Visualization and Computer Graphics},
  volume={14},
  number={6},
  pages={1539--1148},
  year={2008},
  publisher={IEEE}
}

% Fallacies and paradoxes

@inproceedings{Zgraggen2018CHI,
 author = {Zgraggen, Emanuel and Zhao, Zheguang and Zeleznik, Robert and Kraska, Tim},
 title = {Investigating the Effect of the Multiple Comparisons Problem in Visual Analysis},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {479:1--479:12},
 articleno = {479},
 numpages = {12},
 url = {doi.acm.org/10.1145/3173574.3174053},
 url={dx.doi.org/10.1145/3173574.3174053},
 acmid = {3174053},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {experiment, multiple comparisons problem, statistics, visual analysis, visualization},
}

@article{Armstrong2014,
  title={Visualizing statistical mix effects and simpson's paradox},
  author={Armstrong, Zan and Wattenberg, Martin},
  journal={IEEE transactions on visualization and computer graphics},
  volume={20},
  number={12},
  pages={2132--2141},
  year={2014},
  publisher={IEEE}
}

@inproceedings{Alipourfard2018WSDM,
 author = {Alipourfard, Nazanin and Fennell, Peter G. and Lerman, Kristina},
 title = {Can You Trust the Trend?: Discovering Simpson's Paradoxes in Social Data},
 booktitle = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
 series = {WSDM '18},
 year = {2018},
 isbn = {978-1-4503-5581-0},
 location = {Marina Del Rey, CA, USA},
 pages = {19--27},
 numpages = {9},
 url = {doi.acm.org/10.1145/3159652.3159684},
 url={dx.doi.org/10.1145/3159652.3159684},
 acmid = {3159684},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative and social computing systems and tools, ecological fallacies, exploratory data analysis, regression analysis, simpson's paradox, statistical paradigms},
}

@article{Kim2017,
abstract = {We present GraphScape, a directed graph model of the vi-sualization design space that supports automated reasoning about visualization similarity and sequencing. Graph nodes represent grammar-based chart specifications and edges rep-resent edits that transform one chart to another. We weight edges with an estimated cost of the difficulty of interpreting a target visualization given a source visualization. We con-tribute (1) a method for deriving transition costs via a partial ordering of edit operations and the solution of a resulting lin-ear program, and (2) a global weighting term that rewards consistency across transition subsequences. In a controlled experiment, subjects rated visualization sequences covering a taxonomy of common transition types. In all but one case, GraphScape's highest-ranked suggestion aligns with subjects' top-rated sequences. Finally, we demonstrate applications of GraphScape to automatically sequence visualization presen-tations, elaborate transition paths between visualizations, and recommend design alternatives (e.g., to improve scalability while minimizing design changes).},
author = {Kim, Younghoon and Wongsuphasawat, Kanit and Hullman, Jessica and Heer, Jeffrey},
url={dx.doi.org/10.1145/3025453.3025866},
file = {:Users/dorislee/Dropbox/Papers/Kim et al.{\_}2017{\_}GraphScape A Model for Automated Reasoning about Visualization Similarity and Sequencing.pdf:pdf},
isbn = {9781450346559},
journal = {Proc. of ACM CHI 2017},
keywords = {UI Author Keywords visualization,automated design,model,sequence,transition},
mendeley-groups = {HILDA,HILDA/CHI-data-papers,viz-rec/CHI},
title = {{GraphScape: A Model for Automated Reasoning about Visualization Similarity and Sequencing}},
year = {2017}
}
@article{Hullman2017,
 author = {Hullman, Jessica and Kosara, Robert and Lam, Heidi},
 title = {Finding a Clear Path: Structuring Strategies for Visualization Sequences},
 journal = {Comput. Graph. Forum},
 issue_date = {June 2017},
 volume = {36},
 number = {3},
 month = jun,
 year = {2017},
 issn = {0167-7055},
 pages = {365--375},
 numpages = {11},
 url = {doi.org/10.1111/cgf.13194},
 url={dx.doi.org/10.1111/cgf.13194},
 acmid = {3128430},
 publisher = {The Eurographs Association \&\#38; John Wiley \&\#38; Sons, Ltd.},
 address = {Chichester, UK},
 keywords = {Categories and Subject Descriptors according to ACM CCS, H.5.2 [Information Interfaces and Presentation]: User Interfaces-Graphical User Interfaces GUI},
}

@article{ErnstAlthaus2009,
author = {Ernst Althaus and Markus Blumenstock and Disterhoft, Alexej and Andreas Hildebrandt and Markus Krupp},
url={dx.doi.org/10.1007/978-3-642-02026-1},
isbn = {978-3-642-02025-4},
issn = {0302-9743},
keywords = {bioinformatics,gene regulation,heuristics,k -cardinality tree,linear programming,tion},
mendeley-groups = {viz-rec},
pages = {313--321},
title = {{Algorithms for the Maximum Weight Connected k-Induced Subgraph Problem}},
url = {dl.acm.org/citation.cfm?id=1574064.1574101},
volume = {5573},
year = {2009}
}
@article{Ehsan2016,
abstract = {To support effective data exploration, there is a well-recognized need for solutions that can automatically rec-ommend interesting visualizations, which reveal useful insights into the analyzed data. However, such visualizations come at the expense of high data processing costs, where a large number of views are generated to evaluate their usefulness. Those costs are further escalated in the presence of numerical dimensional attributes, due to the potentially large number of possible binning aggregations, which lead to a drastic increase in the number of possible visualizations. To address that challenge, in this paper we propose the MuVE scheme for Multi-Objective View Recommendation for Visual Data Exploration. MuVE introduces a hybrid multi-objective utility function, which captures the impact of binning on the utility of visualizations. Consequently, novel algorithms are proposed for the efficient recommendation of data visualizations that are based on numerical dimensions. The main idea underlying MuVE is to incrementally and progressively assess the different benefits provided by a visualization, which allows an early pruning of a large number of unnecessary op-erations. Our extensive experimental results show the significant gains provided by our proposed scheme.},
author = {Ehsan, Humaira and Sharaf, Mohamed A and Chrysanthis, Panos K},
file = {:Users/dorislee/Box/Papers/0cdd343227a6c10104216fb86cbbdd9d8678.pdf:pdf},
journal = {2016 IEEE 32nd International Conference on Data Engineering, ICDE 2016},
mendeley-groups = {HILDA/Viz/System/VizRec},
title = {{MuVE: Efficient Multi-Objective View Recommendation for Visual Data Exploration}},
year = {2016}
}

@article{Geng,
abstract = {See, stats, and : https : / / www . researchgate . net / publication / 220566216 Interestingness : A survey Article Impact : 3 . 37 : 10 . 1145 / 1132960 . 1132963 : DBLP CITATIONS 541 READS 1 , 080 2 , including : Howard . Hamilton University 176 , 957 SEE All - text , letting . Available : Howard . Hamilton Retrieved : 10 Interestingness measures play an important role in data mining , regardless of the kind of patterns being mined . These measures are intended for selecting and ranking patterns according to their potential interest to the user . Good measures also allow the time and space costs of the mining process to be reduced . This survey reviews the interestingness measures for rules and summaries , classifies them from several perspectives , compares their properties , identifies their roles in the data mining process , gives strategies for selecting appropriate measures for applications , and identifies opportunities for future research in this area .},
author = {Geng, Liqiang and Hamilton, Howard J},
url={dx.doi.org/10.1145/1132960.1132963},
file = {:Users/dorislee/Dropbox/Papers/Geng, Hamilton{\_}Unknown{\_}Interestingness Measures for Data Mining A Survey.pdf:pdf},
keywords = {Algorithms,Categories and Subject Descriptors,Database Applications—Data mining General Terms,H 2 8 [ Database Management ],Knowledge discovery,Measurement Additional Key Words and Phrases,association rules,classification rules,interest measures,interestingness measures,summaries},
title = {{Interestingness Measures for Data Mining : A Survey}}
}
@article{Freitas,
abstract = {Most of the literature argues that surprisingness is an inherently subjective aspect of the discovered knowledge, which cannot be measured in objective terms. This paper departs from this view, and it has a twofold goal: (1) showing that it is indeed possible to define objective (rather than subjective) measures of discovered rule surprisingness; (2) proposing new ideas and methods for defining objective rule surprisingness measures.},
author = {Freitas, Alex A},
file = {::},
title = {{On Objective Measures of Rule Surprisingness}},
url = {www.dainf.cefetpr.br/{~}alex}
}
@article{Silberschatz,
abstract = {One of the central problems in the field of knowledge discovery is the development of good measures of in-terestingness of discovered patterns. Such measures of interestingness are divided into objective measures -those that depend only on the structure of a pat-tern and the underlying data used in the discovery process, and the subjective measures -those that also depend on the class of users who examine the pattern. The purpose of this paper is to lay the groundwork for a comprehensive study of subjective measures of interestingness. In the paper, we clas-sify these measures into actionable and unexpected, and examine the relationship between them. The unexpected measure of interestingness is defined in terms of the belief system that the user has. Inter-estingness of a pattern is expressed in terms of how it affects the belief system.},
author = {Silberschatz, Avi},
file = {:Users/dorislee/Dropbox/Papers/Silberschatz{\_}Unknown{\_}On Subjective Measures of Interestingness in Knowledge Discovery.pdf:pdf},
title = {{On Subjective Measures of Interestingness in Knowledge Discovery}}
}
@article{Mcgarry2005,
abstract = {It is a well known fact that the data mining process can generate many hundreds and often thousands of patterns from data. The task for the data miner then becomes one of determining the most useful patterns from those that are trivial or are already well known to the organization. It is therefore necessary to filter out those patterns through the use of some measure of the patterns actual worth. This article presents a review of the available literature on the various measures devised for evaluating and ranking the discovered patterns produced by the data mining process. These so called interestingness measures are generally divided into two categories: objective measures based on the statistical strengths or properties of the discovered patterns and subjective measures which are derived from the user's beliefs or expectations of their particular problem domain. We evaluate the strengths and weaknesses of the various interestingness measures with respect to the level of user integration within the discovery process.},
author = {Mcgarry, Ken},
url={dx.doi.org/10.1017/S000000000000000},
file = {::},
journal = {The Knowledge Engineering Review},
pages = {1--24},
publisher = {Cambridge University Press},
title = {{A Survey of Interestingness Measures for Knowledge Discovery}},
volume = {000},
year = {2005}
}
@article{Sarawagi2000,
abstract = {In this paper we present a tool for enhanced exploration of OLAP data that is adaptive to a user's prior knowledge of the data. The tool continuously keeps track of the parts of the cube that a user has visited. The information in these scattered visited parts of the cube is pieced together to form a model of the user's expected values in the unvisited parts. The mathematical foundation for this modeling is provided by the classical Maximum Entropy principle. At any time, the user can query for ...},
author = {Sarawagi, S.},
file = {:Users/dorislee/Dropbox/Papers/Sarawagi{\_}2000{\_}User-adaptive exploration of multidimensional data.pdf:pdf},
isbn = {1558607153},
journal = {Proc of the 26th Intl Conference on Very Large},
pages = {307--316},
title = {{User-adaptive exploration of multidimensional data}},
url = {citeseer.ist.psu.edu/sarawagi00useradaptive.html},
year = {2000}
}
@article{Sarawagi1998,
author = {Sarawagi, S and Agrawal, R and Megiddo, N and {Univ Politecn Valencia}, Generalitat Valenciana Ajuntament Valencia and {Edbt Fdn}, E T H Zurich Oracle Sybase Softlab Iberia},
file = {:Users/dorislee/Dropbox/Papers/Sarawagi et al.{\_}1998{\_}Discovery-driven exploration of OLAP data cubes.pdf:pdf},
isbn = {3-540-64264-1},
issn = {03029743},
journal = {6th International Conference on Extending Database Technology (EDBT 98)},
pages = {168--182},
title = {{Discovery-driven exploration of OLAP data cubes}},
year = {1998}
}
@article{Anand2015,
author = {Anand, Anushka and Talbot, Justin},
url={dx.doi.org/10.1109/TVCG.2015.2467323},
file = {:Users/dorislee/Dropbox/Papers/Anand, Talbot{\_}2015{\_}Automatic Selection of Partitioning Variables for Small Multiple Displays.pdf:pdf},
number = {c},
title = {{Automatic Selection of Partitioning Variables for Small Multiple Displays}},
volume = {2626},
year = {2015}
}
@article{Vartak2015,
  title={SeeDB: efficient data-driven visualization recommendations to support visual analytics},
  author={Vartak, Manasi and Rahman, Sajjadur and Madden, Samuel and Parameswaran, Aditya and Polyzotis, Neoklis},
  journal={Proceedings of the VLDB Endowment},
  volume={8},
  number={13},
  pages={2182--2193},
  year={2015},
  publisher={VLDB Endowment},
  url={dx.doi.org/10.14778/2831360.2831371}
}
@article{Wongsuphasawat2016,
abstract = {General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.},
author = {Wongsuphasawat, Kanit and Moritz, Dominik and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
url={dx.doi.org/10.1109/TVCG.2015.2467191},
file = {:Users/dorislee/Dropbox/Papers/Wongsuphasawat et al.{\_}2016{\_}Voyager Exploratory Analysis via Faceted Browsing of Visualization Recommendations.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Browsers,Compass,Data visualization,Encoding,Grammar,Image color analysis,Visualization},
mendeley-groups = {HILDA/Viz/System/VizRec},
number = {1},
pages = {649--658},
title = {{Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations}},
volume = {22},
year = {2016}
}
@article{Sarawagi1999,
abstract = {Our goal is to enhance multidimensional database systems with advanced mining prim- itives. Current Online Analytical Processing (OLAP) products provide a minimal set of basic aggregate operators like sum and aver- age and a set of basic navigational operators like drill-downs and roll-ups. These operators have to be driven entirely by the analyst's in- tuition. Such ad hoc exploration gets tedious and error-prone as data dimensionality and size increases. In earlier work we presented one such advanced primitive where we pre- mined OLAP data for exceptions, summarized the exceptions at appropriate levels, and used them to lead the analyst to the interesting re- gions. In this paper we present a second enhance- ment: a single operator that lets the ana- lyst get summarized reasons for drops or in- creases observed at an aggregated level. This eliminates the need to manually drill-down for such reasons. We develop an information the- oretic formulation for expressing the reasons that is compact and easy to interpret. We de- sign a dynamic programming algorithm that requires only one pass of the data improv- ing significantly over our initial greedy algo- rithm that required multiple passes. In ad- dition, the algorithm uses a small amount of Part of the work was done when the author was at IBM ∗ Almaden Research Center, USA Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 25th VLDB Conference, Edinburgh, Scotland, 1999. memory independent of the data size. This allows easy integration with existing OLAP products. We illustrate with our prototype on the DB2/UDB ROLAP product with the Excel Pivot-table frontend. Experiments on this prototype using the OLAP data bench- mark demonstrate (1) scalability of our algo- rithm as the size and dimensionality of the cube increases and (2) feasibility of getting in- teractive answers even with modest hardware resources. 1},
author = {Sarawagi, Sunita},
file = {:Users/dorislee/Dropbox/Papers/Sarawagi{\_}1999{\_}Explaining differences in multidimensional aggregates.pdf:pdf},
isbn = {1-55860-615-7},
journal = {Proceedings of the VLDB Endowment},
pages = {42--53},
title = {{Explaining differences in multidimensional aggregates}},
year = {1999}
}

@article{Wu2017,
author = {Wu, Yifan and Xu, Larry and Chang, Remco and Wu, Eugene},
file = {:Users/dorislee/Box/Papers/bayesianvis-decisive17.pdf:pdf},
journal = {Dealing with Cognitive Biases in Visualizations (DECISIVe): a VIS 2017 workshop},
title = {{Towards a Bayesian Model of Data Visualization Cognition}},
year = {2017}
}
@misc{anand,
url = {http://public.tableau.com/profile/anand4683#!/vizhome/InsightsfromKagglesTitanicdataset/Story1},
journal = {Tableau Public},
author = {Anand},
title = {Tableau Public: Insights from Kaggle's Titanic dataset. }
}
@article{Alipourfard2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1801.04385v1},
author = {Alipourfard, Nazanin and Fennell, Peter G. and Lerman, Kristina},
url={dx.doi.org/10.1145/3159652.3159684},
eprint = {arXiv:1801.04385v1},
file = {:Users/dorislee/Box/Papers/1801.04385.pdf:pdf},
isbn = {9781450355810},
journal = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining  - WSDM '18},
keywords = {both genders,ects analysis of trends,lower admissions rates for,s paradox,s paradox also a,simpson,trend analysis,when mea-},
pages = {19--27},
title = {{Can you Trust the Trend?}},
url = {dl.acm.org/citation.cfm?doid=3159652.3159684},
year = {2018}
}

@article{Guo2017,
author = {Guo, Yue and Binnig, Carsten and Kraska, Tim and Darmstadt, T U},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Guo et al. - 2017 - What you see is not what you get ! Detecting Simpson ' s Paradoxes during Data Exploration.pdf:pdf},
isbn = {9781450350297},
journal = {HILDA 2017 - Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
mendeley-groups = {viz-rec/CHI,viz-rec},
title = {{What you see is not what you get ! Detecting Simpson ' s Paradoxes during Data Exploration}},
year = {2017}
}

@article{Segel2010,
abstract = {Data visualization is regularly promoted for its ability to reveal stories within data, yet these {\&}{\#}8220;data stories{\&}{\#}8221; differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Segel, Edward and Heer, Jeffrey},
url={dx.doi.org/10.1109/TVCG.2010.179},
file = {:Users/dorislee/Box/Papers/2010-Narrative-InfoVis.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Narrative visualization,case study,design methods,journalism,social data analysis,storytelling},
number = {6},
pages = {1139--1148},
title = {{Narrative visualization: Telling stories with data}},
volume = {16},
year = {2010}
}

@inproceedings{Boy2015,
 author = {Boy, Jeremy and Detienne, Francoise and Fekete, Jean-Daniel},
 title = {Storytelling in Information Visualizations: Does It Engage Users to Explore Data?},
 booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
 series = {CHI '15},
 year = {2015},
 isbn = {978-1-4503-3145-6},
 location = {Seoul, Republic of Korea},
 pages = {1449--1458},
 numpages = {10},
 url = {doi.acm.org/10.1145/2702123.2702452},
 url={dx.doi.org/10.1145/2702123.2702452},
 acmid = {2702452},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {engagement, narrative visualization, social data analysis, storytelling},
}

@article{Hullman2013,
abstract = {Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.},
author = {Hullman, Jessica and Drucker, Steven and {Henry Riche}, Nathalie and Lee, Bongshin and Fisher, Danyel and Adar, Eytan},
url={dx.doi.org/10.1109/TVCG.2013.119},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Hullman et al. - 2013 - A deeper understanding of sequence in narrative visualization.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data storytelling,narrative structure,narrative visualization},
mendeley-groups = {viz-rec/CHI},
number = {12},
pages = {2406--2415},
pmid = {24051807},
title = {{A deeper understanding of sequence in narrative visualization}},
volume = {19},
year = {2013}
}

@article{Hoque2017,
abstract = {Interactive visual data analysis is most productive when users can focus on answering the questions they have about their data, rather than focusing on how to operate the interface to the analysis tool. One viable approach to engaging users in interactive conversations with their data is a natural language interface to visualizations. These interfaces have the potential to be both more expressive and more accessible than other interaction paradigms. We explore how principles from language pragmatics can be applied to the flow of visual analytical conversations, using natural language as an input modality. We evaluate the effectiveness of pragmatics support in our system Evizeon, and present design considerations for conversation interfaces to visual analytics tools.},
author = {Hoque, Enamul and Setlur, Vidya and Tory, Melanie and Dykeman, Isaac},
url={dx.doi.org/10.1109/TVCG.2017.2744684},
file = {:Users/dorislee/Box/Papers/VAST2017{\_}105.pdf:pdf},
isbn = {1077-2626 VO  - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Coherence,Data visualization,Natural languages,Pragmatics,Tools,Visual analytics,ambiguity,feedback,interaction,language pragmatics,natural language,visual analytics},
number = {c},
title = {{Applying Pragmatics Principles for Interaction with Visual Analytics}},
year = {2017}
}

@misc{mushroom,
author = "Schlimmer, Jeff",
year = "1987",
title = "Mushroom Data Set. {UCI} Machine Learning Repository",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@misc{autism,
author = "Fayez Thabtah, Fadi",
year = "2017",
title = "Autism Screening Adult Data Set. {UCI} Machine Learning Repository",
institution = "University of California, Irvine, School of Information and Computer Sciences"}

@misc{titanic,
title = "Titanic: Machine Learning from Disaster. {Kaggle}.",
year="2017",
url="http://www.kaggle.com/c/titanic",
institution = "Kaggle" }

@misc{police,
author = "Pierson, E. and Simoiu, C. and Overgoor, J. and Corbett-Davies, S. and  Ramachandran, V. and Phillips, C. and Goel, S.",
year = "2017",
title = "A large-scale analysis of racial disparities in police stops across the United States",
url = "http://openpolicing.stanford.edu/data/",
institution = "The Stanford Open Policing Project"}

@article{levene2003snowflake,
  title={Why is the snowflake schema a good data warehouse design?},
  author={Levene, Mark and Loizou, George},
  journal={Information Systems},
  volume={28},
  number={3},
  pages={225--240},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{Binnig2017,
  author = {Binnig, Carsten and Stefani, Lorenzo De and Kraska, Tim and Upfal, Eli and Zgraggen, Emanuel and Zhao, Zheguang},
  biburl = {http://www.bibsonomy.org/bibtex/2f831f5c3d3091733a16707e4f12274e8/kraska},
  booktitle = {{CIDR} 2017, 8th Biennial Conference on Innovative Data Systems Research,
               Chaminade, CA, USA, January 8-11, 2017},
  title = {Toward Sustainable Insights, or Why Polygamy is Bad for You},
  url = {cidrdb.org/cidr2017/papers/p56-binnig-cidr17.pdf},
  year = 2017
}
@article{Xin2007,
abstract = {Data cube computation is one of the most es-sential but expensive operations in data ware-housing. Previous studies have developed two major approaches, top-down vs. bottom-up. The former, represented by the Multi-Way Array Cube (called MultiWay) algorithm [25], aggregates simultaneously on multiple dimensions; however, it cannot take advan-tage of Apriori pruning [2] when computing iceberg cubes (cubes that contain only ag-gregate cells whose measure value satisfies a threshold, called iceberg condition). The latter, represented by two algorithms: BUC [6] and H-Cubing[11], computes the iceberg cube bottom-up and facilitates Apriori prun-ing. BUC explores fast sorting and partition-ing techniques; whereas H-Cubing explores a data structure, H-Tree, for shared computa-tion. However, none of them fully explores multi-dimensional simultaneous aggregation. In this paper, we present a new method, Star-Cubing, that integrates the strengths of the previous three algorithms and performs ag-gregations on multiple dimensions simultane-ously. It utilizes a star-tree structure, ex-tends the simultaneous aggregation methods, and enables the pruning of the group-by's that do not satisfy the iceberg condition. Our performance study shows that Star-Cubing is highly efficient and outperforms all the previ-ous methods in almost all kinds of data distri-butions.},
author = {Xin, Dong and Han, Jiawei and Li, Xiaolei and Shao, Zheng and Wah, Benjamin W.},
url={dx.doi.org/10.1109/TKDE.2007.250589},
file = {:Users/dorislee/Box/Papers/S15P02.pdf:pdf},
isbn = {0-12-722442-4},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Data mining,Data warehouse,Online analytical processing (OLAP)},
number = {1},
pages = {111--126},
title = {{Computing iceberg cubes by top-down and bottom-up integration: The starcubing approach}},
volume = {19},
year = {2007}
}

@article{Parameswaran2010,
abstract = {We consider the problem of recommending the best set of k items when there is an inherent ordering between items, expressed as a set of prerequisites (e.g., the movie ‘Godfather I' is a prerequi- site of ‘Godfather II'). Since this general problem is computation- ally intractable, we develop 3 approximation algorithms to solve this problem for various prerequisite structures (e.g., chain graphs, AND graphs, AND-OR graphs). We derive worst-case bounds for these algorithms for these structures, and experimentally evaluate these algorithms on synthetic data. We also develop an algorithm to combine solutions in order to generate even better solutions, and compare the performance of this algorithm with the other three.},
author = {Parameswaran, Aditya G. and Garcia-Molina, Hector and Ullman, Jeffrey D.},
url = {dx.doi.org/10.1145/1871437.1871555},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Parameswaran, Garcia-Molina, Ullman - 2010 - Evaluating, combining and generalizing recommendations with prerequisites.pdf:pdf},
isbn = {9781450300995},
journal = {Proceedings of the 19th ACM international conference on Information and knowledge management - CIKM '10},
keywords = {graph theory,prerequisites,recommendation algorithms},
mendeley-groups = {viz-rec},
pages = {919},
title = {{Evaluating, combining and generalizing recommendations with prerequisites}},
year = {2010}
}

@article{Wall2017,
abstract = {Visual analytic tools combine the complementary strengths of hu-mans and machines in human-in-the-loop systems. Humans provide invaluable domain expertise and sensemaking capabilities to this discourse with analytic models; however, little consideration has yet been given to the ways inherent human biases might shape the visual analytic process. In this paper, we establish a conceptual framework for considering bias assessment through human-in-the-loop systems and lay the theoretical foundations for bias measurement. We pro-pose six preliminary metrics to systematically detect and quantify bias from user interactions and demonstrate how the metrics might be implemented in an existing visual analytic system, InterAxis. We discuss how our proposed metrics could be used by visual ana-lytic systems to mitigate the negative effects of cognitive biases by making users aware of biased processes throughout their analyses.},
author = {Wall, Emily and Blaha, Leslie M and Franklin, Lyndsey and Endert, Alex},
isbn = {9781538631638},
journal = {2017 IEEE Conference on Visual Analytics Science and Technology (VAST)},
keywords = {0,5,cognitive bias,h,human-computer,human-in-the-loop,index terms,information systems,mixed initiative,user interaction,visual analytics},
title = {{Warning, Bias May Occur: A Proposed Approach to Detecting Cognitive Bias in Interactive Visual Analytics}},
year = {2017}
}

@article{Sarvghad2017,
abstract = {Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets [30] to incorporate dimension coverage of the analysts' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one's own analysis history, and offers a different perspective on one's past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.},
author = {Sarvghad, Ali and Tory, Melanie and Mahyar, Narges},
url={dx.doi.org/10.1109/TVCG.2016.2598466},
file = {:Users/dorislee/Box/Papers/07534787.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Dimension coverage,Empirical laboratory study,Exploratory data analysis,History,Scented widgets,Tabular data},
number = {1},
pages = {21--30},
title = {{Visualizing Dimension Coverage to Support Exploratory Analysis}},
volume = {23},
year = {2017}
}

@article{Mackinlay2007,
abstract = {This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.},
author = {Mackinlay, Jock D. and Hanrahan, Pat and Stolte, Chris},
url={dx.doi.org/10.1109/TVCG.2007.70594},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Mackinlay, Hanrahan, Stolte - 2007 - Show Me Automatic presentation for visual analysis.pdf:pdf},
isbn = {1077-2626 VO  - 13},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Automatic presentation,Best practices,Data visualization,Graphic design,Small multiples,Visual analysis},
number = {6},
pages = {1137--1144},
pmid = {17968057},
title = {{Show Me: Automatic presentation for visual analysis}},
volume = {13},
year = {2007}
}
@article{Wu2013,
abstract = {Database users commonly explore large data sets by running ag-gregate queries that project the data down to a smaller number of points and dimensions, and visualizing the results. Often, such vi-sualizations will reveal outliers that correspond to errors or surpris-ing features of the input data set. Unfortunately, databases and vi-sualization systems do not provide a way to work backwards from an outlier point to the common properties of the (possibly many) unaggregated input tuples that correspond to that outlier. We pro-pose Scorpion, a system that takes a set of user-specified outlier points in an aggregate query result as input and finds predicates that explain the outliers in terms of properties of the input tuples that are used to compute the selected outlier results. Specifically, this explanation identifies predicates that, when applied to the in-put data, cause the outliers to disappear from the output. To find such predicates, we develop a notion of influence of a predicate on a given output, and design several algorithms that efficiently search for maximum influence predicates over the input data. We show that these algorithms can quickly find outliers in two real data sets (from a sensor deployment and a campaign finance data set), and run orders of magnitude faster than a naive search algorithm while providing comparable quality on a synthetic data set.},
author = {Wu, Eugene and Madden, Samuel},
url={dx.doi.org/10.14778/2536354.2536356},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Wu, Madden - 2013 - Scorpion Explaining Away Outliers in Aggregate Queries.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
mendeley-groups = {Database Usability},
number = {8},
pages = {553--564},
title = {{Scorpion: Explaining Away Outliers in Aggregate Queries}},
volume = {6},
year = {2013}
}

@article{Heer2012,
abstract = {The increasing scale and availability of digital data provides an extraordinary resource for informing public policy, scientific discovery, business strategy, and even our personal lives. To get the most out of such data, however, users must be able to make sense of it: to pursue questions, uncover patterns of interest, and identify (and potentially correct) errors. In concert with data-management systems and statistical algorithms, analysis requires contextualized human judgments regarding the domain-specific significance of the clusters, trends, and outliers discovered in data. Visualization provides a powerful means of making sense of data. By mapping data attributes to visual properties such as position, size, shape, and color, visualization designers leverage perceptual skills to help users discern and interpret patterns within data.11 A single image, however, typically provides answers to, at best, a handful of questions. Instead, visual analysis typically progresses in an iterative process of view creation, exploration, and refinement. Meaningful analysis consists of repeated explorations as users develop insights about significant relationships, domain-specific contextual influences, and causal patterns. Confusing widgets, complex dialog boxes, hidden operations, incomprehensible displays, or slow response times can limit the range and depth of topics considered and may curtail thorough deliberation and introduce errors. To be most effective, visual analytics tools must support the fluent and flexible use of visualizations at rates resonant with the pace of human thought. The goal of this article is to assist designers, researchers, professional analysts, procurement officers, educators, and students in evaluating and creating visual analysis tools. We present a taxonomy of interactive dynamics that contribute to successful analytic dialogues. The taxonomy consists of 12 task types grouped into three high-level categories, as shown in table 1: (1) data and view specification (visualize, filter, sort, and derive); (2) view manipulation (select, navigate, coordinate, and organize); and (3) analysis process and provenance (record, annotate, share, and guide). These categories incorporate the critical tasks that enable iterative visual analysis, including visualization creation, interactive querying, multiview coordination, history, and collaboration. Validating and evolving this taxonomy is a community project that proceeds through feedback, critique, and refinement. Our focus on interactive elements presumes a basic familiarity with visualization design. The merits and frailties of bar charts, scatter plots, timelines, and node-link diagrams, and of the visual-encoding decisions that underlie such graphics, are certainly a central concern, but we will largely pass over them here. A number of articles and books address these topics in great detail,11,12,16,52 and we recommend them to interested readers. Within each branch of the taxonomy presented here, we describe example systems that exhibit useful interaction techniques. To be clear, these examples do not constitute an exhaustive survey; rather, each is intended to convey the nature and diversity of interactive operations. Throughout the article the term analyst refers to someone who uses visual analysis tools and not to a specific person or role. Our notion of analyst encompasses anyone seeking to understand data: traditional analysts investigating financial markets or terrorist networks, scientists uncovering new insights, journalists piecing together a story, and people tracking various facets of their lives, including blood pressure, money spent, electricity used, or miles traveled.},
author = {Heer, Jeffrey and Shneiderman, Ben},
url={dx.doi.org/10.1145/2133416.2146416},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Heer, Shneiderman, Park - 2012 - A taxonomy of tools that support the fluent and flexible use of visualizations.pdf:pdf},
isbn = {1542-7730},
issn = {15427730},
journal = {Queue},
keywords = {filter},
mendeley-groups = {HILDA/Viz/Theory/Reviews},
number = {2},
pages = {30},
title = {{Interactive Dynamics for Visual Analysis}},
url = {dl.acm.org/citation.cfm?doid=2133416.2146416},
volume = {10},
year = {2012}
}

@misc{ctrp3,
  title = {Connecticut Racial Profiling Prohibition Project Data Portal},
  howpublished = {\url{ctrp3.ctdata.org/}},
  year = "2017",
  note = {Accessed: 2018-07-16}
}

@Article{Gray1997,
author="Gray, Jim
and Chaudhuri, Surajit
and Bosworth, Adam
and Layman, Andrew
and Reichart, Don
and Venkatrao, Murali
and Pellow, Frank
and Pirahesh, Hamid",
title="Data Cube: A Relational Aggregation Operator Generalizing Group-By, Cross-Tab, and Sub-Totals",
journal="Data Mining and Knowledge Discovery",
year="1997",
month="Mar",
day="01",
volume="1",
number="1",
pages="29--53",
abstract="Data analysis applications typically aggregate data across manydimensions looking for anomalies or unusual patterns. The SQL aggregatefunctions and the GROUP BY operator produce zero-dimensional orone-dimensional aggregates. Applications need the N-dimensionalgeneralization of these operators. This paper defines that operator, calledthe data cube or simply cube. The cube operator generalizes the histogram,cross-tabulation, roll-up,drill-down, and sub-total constructs found in most report writers.The novelty is that cubes are relations. Consequently, the cubeoperator can be imbedded in more complex non-procedural dataanalysis programs. The cube operator treats each of the Naggregation attributes as a dimension of N-space. The aggregate ofa particular set of attribute values is a point in this space. Theset of points forms an N-dimensional cube. Super-aggregates arecomputed by aggregating the N-cube to lower dimensional spaces.This paper (1) explains the cube and roll-up operators, (2) showshow they fit in SQL, (3) explains how users can define new aggregatefunctions for cubes, and (4) discusses efficient techniques tocompute the cube. Many of these features are being added to the SQLStandard.",
issn="1573-756X",
url="doi.org/10.1023/A:1009726021843"
}

@Article{Itti2009,
author={Itti, Laurent
and Baldi, Pierre},
title={Bayesian surprise attracts human attention},
journal={Vision Research},
year={2009},
month={May},
day={19},
volume={49},
number={10},
pages={1295-1306},
abstract={We propose a formal Bayesian definition of surprise to capture subjective aspects of sensory information. Surprise measures how data affects an observer, in terms of differences between posterior and prior beliefs about the world. Only data observations which substantially affect the observer's beliefs yield surprise, irrespectively of how rare or informative in Shannon's sense these observations are. We test the framework by quantifying the extent to which humans may orient attention and gaze towards surprising events or items while watching television. To this end, we implement a simple computational model where a low-level, sensory form of surprise is computed by simple simulated early visual neurons. Bayesian surprise is a strong attractor of human attention, with 72\% of all gaze shifts directed towards locations more surprising than the average, a figure rising to 84\% when focusing the analysis onto regions simultaneously selected by all observers. The proposed theory of surprise is applicable across different spatio-temporal scales, modalities, and levels of abstraction.},
issn={0042-6989},
url ={dx.doi.org/10.1016/j.visres.2008.09.007}
}

@article{Correll2016,
author = {Correll, Michael and Heer, Jeffrey},
url={dx.doi.org/10.1109/TVCG.2016.2598618},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Correll, Heer - 2016 - Surprise! Bayesian Weighting for De-Biasing Thematic Maps.pdf:pdf},
isbn = {1077-2626},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
mendeley-groups = {HILDA/Viz/System/VizRec,viz-rec/CHI},
number = {c},
pages = {1--1},
title = {{Surprise! Bayesian Weighting for De-Biasing Thematic Maps}},
url = {ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7536212},
volume = {2626},
year = {2016}
}

@misc{exitpolls,
year = "2016",
title = "Elections 2016 Exit Polls",
institution = "CNN",
url="http://edition.cnn.com/election/2016/results/exit-polls"}

@Article{McHugh2013,
author={McHugh, Mary L.},
title={The Chi-square test of independence},
journal={Biochemia Medica},
year={2013},
month={Jun},
day={15},
publisher={Croatian Society of Medical Biochemistry and Laboratory Medicine},
volume={23},
number={2},
pages={143-149},
abstract={The Chi-square statistic is a non-parametric (distribution free) tool designed to analyze group differences when the dependent variable is measured at a nominal level. Like all non-parametric statistics, the Chi-square is robust with respect to the distribution of the data. Specifically, it does not require equality of variances among the study groups or homoscedasticity in the data. It permits evaluation of both dichotomous independent variables, and of multiple group studies. Unlike many other non-parametric and some parametric statistics, the calculations needed to compute the Chi-square provide considerable information about how each of the groups performed in the study. This richness of detail allows the researcher to understand the results and thus to derive more detailed information from this statistic than from many others. The Chi-square is a significance statistic, and should be followed with a strength statistic. The Cramer's V is the most common strength test used to test the data when a significant Chi-square result has been obtained. Advantages of the Chi-square include its robustness with respect to distribution of the data, its ease of computation, the detailed information that can be derived from the test, its use in studies for which parametric assumptions cannot be met, and its flexibility in handling data from both two group and multiple group studies. Limitations include its sample size requirements, difficulty of interpretation when there are large numbers of categories (20 or more) in the independent or dependent variables, and tendency of the Cramer's V to produce relative low correlation measures, even for highly significant results.},
issn={1330-0962},
url={ncbi.nlm.nih.gov/pmc/articles/PMC3900058/}
}
@book{Han2005,
 author = {Han, Jiawei},
 title = {Data Mining: Concepts and Techniques},
 year = {2005},
 isbn = {1558609016},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}
@inproceedings{Ankerst1999,
 author = {Ankerst, Mihael and Elsen, Christian and Ester, Martin and Kriegel, Hans-Peter},
 title = {Visual Classification: An Interactive Approach to Decision Tree Construction},
 booktitle = {Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '99},
 year = {1999},
 isbn = {1-58113-143-7},
 location = {San Diego, California, USA},
 pages = {392--396},
 numpages = {5},
 url = {doi.acm.org/10.1145/312129.312298},
 acmid = {312298},
 publisher = {ACM},
 address = {New York, NY, USA},
}
@article{Quinlan1986,
 author = {Quinlan, J. R.},
 title = {Induction of Decision Trees},
 journal = {Mach. Learn.},
 volume = {1},
 number = {1},
 month = mar,
 year = {1986},
 issn = {0885-6125},
 pages = {81--106},
 numpages = {26},
 url = {dx.doi.org/10.1023/A:1022643204877},
 url={dx.doi.org/10.1023/A:1022643204877},
 acmid = {637969},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {classification, decision trees, expert systems, induction, information theory, knowledge acquisition},
}
@misc{Terence2018,
url = {explained.ai/decision-tree-viz/},
journal = {Explained.ai},
month = {September},
year = {2018},
author = {Parr, Terence and Grover, Prince},
title = {How to visualize decision trees}
}
@misc{Hermann2017,
url = {http://eng.uber.com/michelangelo/},
journal = {Uber Engineering},
month = {September},
year = {2017},
author = {Hermann, Jeremy and Del Balso, Mike},
title = {Meet Michelangelo: Uber's Machine Learning Platform}
}
@inproceedings{Kandel2012,
  title = {Profiler: Integrated Statistical Analysis and Visualization for Data Quality Assessment},
  author = {Sean Kandel AND Ravi Parikh AND Andreas Paepcke AND Joseph Hellerstein AND Jeffrey Heer},
  booktitle = {Advanced Visual Interfaces},
  year = {2012},
  url = {http://vis.stanford.edu/papers/profiler}
}
@article{Joglekar2015,
abstract = {We present a data exploration system equipped with smart drill-down, a novel operator for interactively exploring a relational table to discover and summarize " interesting " groups of tuples. Each such group of tuples is represented by a rule. For instance, the rule (a, b, 1000) tells us that there are a thousand tuples with value a in the first column and b in the second column (and any value in the third column). Smart drill-down presents an analyst with a list of rules that together describe interesting aspects of the table. The analyst can tailor the definition of interesting, and can interactively apply smart drill-down on an existing rule to explore that part of the table. In the demonstration, conference attendees will be able to use the data exploration system equipped with smart drill-down, and will be able to contrast smart drill-down to traditional drill-down, for various interestingness measures, and resource constraints.},
author = {Joglekar, Manas and Garcia-molina, Hector and Parameswaran, Aditya},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Joglekar, Garcia-molina, Parameswaran - 2015 - Smart Drill-Down A New Data Exploration Operator.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the 41st International Conference on Very Large Data Bases},
mendeley-groups = {Database Usability},
number = {12},
pages = {1928--1931},
title = {{Smart Drill-Down : A New Data Exploration Operator}},
volume = {8},
year = {2015}
}

@article{Lee2018,
author = {Lee, Doris Jung-Lin and Parameswaran, Aditya},
journal = {IEEE Bulletin of Technical Committee on Data Engineering},
title = {{The Case for a Visual Discovery Assistant: A Holistic Solution for Accelerating Visual Data Exploration}},
year = {2018}
}
@article{Vartak2017,
 author = {Vartak, Manasi and Huang, Silu and Siddiqui, Tarique and Madden, Samuel and Parameswaran, Aditya},
 title = {Towards Visualization Recommendation Systems},
 journal = {SIGMOD Records},
 issue_date = {December 2016},
 volume = {45},
 number = {4},
 month = may,
 year = {2017},
 issn = {0163-5808},
 pages = {34--39},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3092931.3092937},
 doi = {10.1145/3092931.3092937},
 acmid = {3092937},
 publisher = {ACM},
 address = {New York, NY, USA},
}
@article{Siddiqui2017,
  title={Effortless data exploration with zenvisage: an expressive and interactive visual analytics system},
  author={Tarique Siddiqui and Albert Kim and  John Lee and Karrie Karahalios and Aditya Parameswaran},
  journal={Proceedings of the VLDB Endowment},
  volume={10},
  number={4},
  pages={457--468},
  year={2016},
  publisher={VLDB Endowment},
  doi={10.14778/3025111.3025126}
}

@article{Macke2018,
 author = {Macke, Stephen and Zhang, Yiming and Huang, Silu and Parameswaran, Aditya},
 title = {Adaptive Sampling for Rapidly Matching Histograms},
 journal = {Proc. VLDB Endow.},
 issue_date = {June 2018},
 volume = {11},
 number = {10},
 month = jun,
 year = {2018},
 issn = {2150-8097},
 pages = {1262--1275},
 numpages = {14},
 url = {https://doi.org/10.14778/3231751.3231753},
 doi = {10.14778/3231751.3231753},
 acmid = {3242943},
 publisher = {VLDB Endowment},
}
@misc{ wiki:minimax,
    author = "{Wikipedia contributors}",
    title = "Minimax --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2018",
    url = "https://en.wikipedia.org/w/index.php?title=Minimax&oldid=866945016",
    note = "[Online; accessed 30-December-2018]"
  }

@inproceedings{Ding2016,
 author = {Ding, Bolin and Huang, Silu and Chaudhuri, Surajit and Chakrabarti, Kaushik and Wang, Chi},
 title = {Sample + Seek: Approximating Aggregates with Distribution Precision Guarantee},
 booktitle = {Proceedings of the 2016 International Conference on Management of Data},
 series = {SIGMOD '16},
 year = {2016},
 isbn = {978-1-4503-3531-7},
 location = {San Francisco, California, USA},
 pages = {679--694},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/2882903.2915249},
 doi = {10.1145/2882903.2915249},
 acmid = {2915249},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {approximate query processing, indexing, precision guarantee, sampling},
}


@article{Key2012,
abstract = {We present VizDeck, a web-based tool for exploratory visual analytics of unorganized relational data. Motivated by collaborations with domain scientists who search for com- plex patterns in hundreds of data sources simultaneously, VizDeck automatically recommends appropriate visualiza- tions based on the statistical properties of the data and adopts a card game metaphor to help organize the recom- mended visualizations into interactive visual dashboard ap- plications in seconds with zero programming. The demon- stration allows users to derive, share, and permanently store their own dashboard from hundreds of real science datasets using a production system deployed at the University of Washington.},
author = {Key, Alicia and Howe, Bill and Perry, Daniel and Aragon, Cecilia},
doi = {10.1145/2213836.2213931},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Key et al. - 2012 - VizDeck(2).pdf:pdf},
isbn = {9781450312479},
issn = {07308078},
journal = {Proceedings of the 2012 international conference on Management of Data - SIGMOD '12},
mendeley-groups = {NLP/viz-rec,NLP},
pages = {681},
title = {{VizDeck}},
url = {http://dl.acm.org/citation.cfm?doid=2213836.2213931},
year = {2012}
}

@article{Muller1993,
 author = {Muller, Michael J. and Kuhn, Sarah},
 title = {Participatory Design},
 journal = {Communications of the ACM},
 issue_date = {June 1993},
 volume = {36},
 number = {6},
 month = jun,
 year = {1993},
 issn = {0001-0782},
 pages = {24--28},
 numpages = {5},
 doi = {10.1145/153571.255960},
 acmid = {255960},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Dang2014,
author = {{Tuan Nhon Dang} and {Leland Wilkinson}},
doi = {10.1109/PacificVis.2014.42},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Wilkinson - 2014 - ScagExplorer Exploring Scatterplots by Their Scagnostics.pdf:pdf},
isbn = {978-1-4799-2873-6},
issn = {21658773},
journal = {2014 IEEE Pacific Visualization Symposium},
mendeley-groups = {zenvisage/zv-scatter},
pages = {73--80},
title = {{ScagExplorer: Exploring Scatterplots by Their Scagnostics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6787139},
year = {2014}
}
@article{Wilkinson2005,
author = {Wilkinson, Leland and {Anushka Anand} and {Robert Grossman}},
file = {:Users/dorislee/Box/Papers/Wilkinson{\_}Infovis-05.pdf:pdf},
journal = {IEEE Symposium on Information Visualization (INFOVIS)},
keywords = {statistical graphics,visualization},
title = {{Graph-Theoretic Scagnostics}},
year = {2005}
}
@article{Gotz2016,
abstract = {Large and high-dimensional real-world datasets are being gathered across a wide range of application disciplines to en-able data-driven decision making. Interactive data visualiza-tion can play a critical role in allowing domain experts to se-lect and analyze data from these large collections. However, there is a critical mismatch between the very large number of dimensions in complex real-world datasets and the much smaller number of dimensions that can be concurrently visu-alized using modern techniques. This gap in dimensionality can result in high levels of selection bias that go unnoticed by users. The bias can in turn threaten the very validity of any subsequent insights. In this paper, we present Adaptive Contextualization (AC), a novel approach to interactive visual data selection that is specifically designed to combat the in-visible introduction of selection bias. Our approach (1) moni-tors and models a users visual data selection activity, (2) com-putes metrics over that model to quantify the amount of selec-tion bias after each step, (3) visualizes the metric results, and (4) provides interactive tools that help users assess and avoid bias-related problems. We also share results from a user study which demonstrate the effectiveness of our technique.},
author = {Gotz, David and Sun, Shun and Cao, Nan},
doi = {10.1145/2856767.2856779},
file = {:Users/dorislee/Box/Papers/gotz{\_}iui{\_}2016.pdf:pdf},
isbn = {9781450341370},
journal = {Proceedings of the 21st International Conference on Intelligent User Interfaces - IUI '16},
pages = {85--95},
title = {{Adaptive Contextualization: Combating Bias During High-Dimensional Visualization and Data Selection}},
url = {http://dl.acm.org/citation.cfm?doid=2856767.2856779},
year = {2016}
}
@article{TR,
 author = {Lee, Doris Jung-Lin and Dev, Himel and Hu, Huizi and Elmeleegy, Hazem and Parameswaran, Aditya},
 title = {Avoiding Drill-down Fallacies with VisPilot: Assisted Exploration of Data Subsets (Technical Report)},
 year = {2019}
}
