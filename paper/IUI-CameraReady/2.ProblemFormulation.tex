%!TEX root = main.tex
% \section{Towards Informative Exploration}
\change{\section{Problem Description\label{sec:problem}}}
In this section, we first describe how analysts manually explore the space of data subsets using drill-downs. We then introduce the three design principles aimed at addressing the current challenges of manual exploration, and automatically guide analysts to the key informative insights.
% \subsection{Manual Exploration via Drill-Downs}
\subsection{\change{The Challenge of Manual Drill-Down Exploration}}
During visual data exploration, an analyst may need to explore different subsets of the data, which form a combinatorial \emph{lattice}. Figure 1 shows a partial lattice for the 2016 US election dataset. The lattice contains the overall visualization with no filter at the first level, all visualizations with a single filter at the second level, all visualizations with two filters at third level, and so on. Analysts explore such a combinatorial lattice from top to bottom, by generating and examining visualizations with increasing levels of specificity. In particular, analysts perform drill-downs to access data subsets at lower levels by adding one filter at a time and visualize \change{the measures of interest for each data subset}. Further, as analysts perform drill-downs, they use the most recent visualization in the drill-down path (known as the `parent') as a reference to establish what they expect to see in the new visualization (known as the `child'). For example in Figure~\ref{fig:elections_example}, the visualizations \texttt{Female} and \texttt{Black} are the \emph{parents} of the \texttt{Black Female} visualization, explored along the purple and orange path respectively.
\par As exemplified by the purple path in Figure~\ref{fig:elections_example}, during drill-downs analysts may be misguided by improper references that exhibits high deviation locally, in particular when other potential parents (i.e., parents not explored in the drill-down path) that could explain the more general phenomenon are overlooked. We refer to this misinterpretation as the \emph{drill-down fallacy}, since the fallacy arises from the inductive nature of the drill-down operation.
% \subsection{Three Elements of Informative Exploration}
\subsection{\change{Design Objectives for Informative Exploration}}
Our goal is to help analysts discover the key informative insights in a dataset, while avoiding drill-down fallacies. We argue in favor of three essential principles for finding such insights---namely the three S's: \emph{safety}, \emph{saliency}, and \emph{summarization}. We adopt these principles to develop a visual exploration tool that automatically selects visualizations that collectively convey the key informative insights of a multidimensional dataset.
\subsubsection{Safety}
To prevent the drill-down fallacy, we concentrate on \emph{safety}---using informative references for discovering insights. We identify informative references in a drill-down context by modeling the \emph{informativeness} of an observed parent in characterizing the child visualization. An observed parent is \emph{informative} if its data distribution closely follows the child visualization's data distribution, since the parent serves as a proper reference that helps analysts form an accurate mental picture of what to expect from the child visualization. Specifically, we formulate the informativeness of an observed parent $V_i^j$ for a visualization $V_i$ as the similarity between their data distributions measured using a distance function $D$. \change{The distance $D(V_i, V_i^j)$ is computed based on the probability distributions represented by each visualization (in this case, a vector of bar values). \tr{For example, based on the Figure~\ref{fig:elections_example} example, the Euclidean distance between \texttt{Female} ($V_i^j$=[54,41,5]) and \texttt{Black Female} ($V_i$=[94,4,2]) is
54.57. %sqrt((94-54)**2+(41-4)**2+3**2)
}.}The most informative parents $V_i^*$ for visualization $V_i$ are the ones whose data distributions are most similar to $V_i$.
\begin{equation}
    V_i^*=\{V_i^j : \underset{V_i^j}{argmin}\ D(V_i, V_i^j)\}
\end{equation}
\change{We regard a parent visualization as informative if its distance from the child visualization falls within a threshold $\theta\%$ compared to the most informative parent, set as default as 90\% and adjustable by user if needed.}
\tr{
    We regard a parent visualization as informative if its distance from the child visualization falls within a threshold $\theta\%$ compared to the most informative parent:
    \begin{equation}
        V_i^{*, \theta} = \{V_i^j : \frac{D(V_i, V_i^*)}{D(V_i, V_i^j)} \geq \theta\}
    \end{equation}
    For example in Figure~\ref{fig:elections_example}, while both \texttt{Black} and \texttt{Female} visualizations are considered parents of the \texttt{Black Female} visualization, only the \texttt{Black} visualization is considered an informative parent of the \texttt{Black Female} population, for any values of $\theta \geq 11\%$ via the Euclidean distance metric.
}
Note that our proposed system can work with other common distance metrics such as Kullback-Leibler Divergence and Earth Mover's distance~\cite{Vartak2015}. Without loss of generality, we chose to use Euclidean distance metric for the remainder of our paper.
\subsubsection{Saliency}
To discover insights, we emphasize \emph{saliency}--- identifying interesting visualizations that convey new information. In general, a visualization is deemed to be \emph{interesting} if its underlying data distribution differs from that of its parents, and thus offers new information or unexpected insights. The notion of such interestingness have been explored in past work~\cite{Correll2016,Itti2009,Vartak2015}, particularly through the usage of distance-based metrics, where a large distance from some reference visualization indicates that the selected visualization is interesting. However, unlike past work, we concentrate on \emph{informative interestingness}, where the goal is to identify interesting visualizations in presence of informative references. Specifically, to model the interestingness of a visualization $V_i$ in the context of its informative parent $V_i^*$, we characterize the deviation between their data distributions using $D(V_i, V_i^*)$. Notice that our informativeness objective minimizes the distance between parent and child, whereas interestingness objective maximizes the resultant minimum distance. Accordingly, our overall objective function uses a maximin function of distance to capture informative insights. To incorporate the effect of subpopulation size into our objective function, we multiply the distance $D(V_i, V_i^*)$ between an informative parent $V_i^*$ and a child visualization $V_i$ by the ratio of their sizes  $U(V_i) = \frac{|V_i|}{|V_i^*|} \cdot D(V_i, V_i^*)$.\footnote{If multiple informative parents, $V_i^{*, \theta}$, are selected for a given visualization, $V_i$, then $U(V_i)$ is defined in terms of the most informative {\em selected} parent.}
\subsubsection{Summarization}
To succinctly convey insights, we concentrate on \emph{summarization}---identifying a group of visualizations that collectively contain informative insights. Since our aim is to identify a unified narrative, instead of discrete insights, we enforce that any selected visualization must have at least one of its informative parents present in the dashboard. Specifically, we identify a set of $k$ connected visualizations that collectively maximize the sum of the proposed utility $U(V_i)$ across each selected visualization, $V_i$, and thus succinctly convey informative insights, more formally stated as follows:
\par \textsc{Problem.} \textit{Given a dataset and user-provided X, Y attributes, select $k$ visualizations from the lattice of data subsets $\mathcal{L}$ to be included in the dashboard, such that:
\\ (i) one of the selected visualization is the overall visualization, corresponding to the entire dataset with no filter;
\\ (ii) for each visualization except for the overall, at least one of its informative parents is present in the $k$ visualizations;
\\ (iii) the $k$ selected visualizations maximize the total utility $\sum_{V_i \in \mathcal{L}} U(V_i)$ as defined above.
}% and aggregation function G, a lattice $\mathcal{L}$ consisting of visualizations $V_i$ for all possible filter $F_i$ that could be constructed from dataset D:}
% \\ \texttt{$V_i$ = SELECT X, G(Y) FROM D WHERE $F_i$ GROUP BY X}
% \\ \textit{find k visualizations from $\mathcal{L}$ to include in dashboard $\mathcal{S}$, such that the total utility $\sum_{V_i \in \mathcal{L}} U(V_i)$ as defined above is maximized, while enforcing that all $V_i \in \mathcal{S}$ is connected.}
\par This problem of finding a connected subgraph in the lattice that has the maximum total edge utility is known as the \emph{maximum-weight connected subgraph problem}~\cite{ErnstAlthaus2009} and is known to be NP-Complete~\cite{Parameswaran2010}. We design several approximate algorithms to solve this problem efficiently.
