%!TEX root = main.tex
% \section{Towards Informative Exploration}
\change{\section{Problem Formulation\label{sec:problem}}}
In this section, we first describe how analysts
manually explore the space of data subsets.
We then introduce \change{three design principles
for a system that can automatically guide analysts to the key insights}.
% \subsection{Manual Exploration via Drill-Downs}

\change{\subsection{Manual Exploration: Approach and Challenges}}
During visual data exploration,
an analyst may need to explore different subsets
of the data \change{that together form a combinatorial \emph{lattice}}.
Figure~\ref{fig:elections_example}
shows a partial lattice for the 2016 US election dataset.
The lattice contains the overall visualization
with no filter at the first level,
all visualizations with a single filter
at the second level \change{(such as \fem)},
all visualizations with two filters at third level,
and so on.
Analysts explore such a combinatorial lattice
from top to bottom, by generating and examining
visualizations with increasing levels of specificity.
In particular, analysts perform \emph{drill-downs}~\cite{Gray1997}
to access data subsets at lower levels by
adding one filter at a time
\change{(such as adding \blk to \fem along the purple path)}
and visualize
\change{their measures of interest for each data subset---in
this case the percentage of votes for each candidate}.
Further, as analysts perform drill-downs,
they use the most recent visualization
in the drill-down path---the {\em parent}---as a \change{{\em reference}}
to establish what they expect to see in the
\change{next visualization in the path---the {\em child}}.
In Figure~\ref{fig:elections_example},
the visualizations \fem and \blk
are the \emph{parents} of the \blkfem visualization,
explored along the purple and orange path respectively.

\par \change{As we saw in the purple path
in Figure~\ref{fig:elections_example},
while performing drill-downs,
analysts may detect a local deviation
(we will formalize these and other notions subsequently)
between
a parent and a child to be significant.
For example, they may be surprised by the fact
that the \fem and \blkfem
visualizations are very different from each other,
and may
find this to be a novel insight.
However, this deviation is a result of \fem
not being an
{\em informative}
parent or reference for \blkfem---instead, it is a
{\em deceptive} reference.
Here, a different parent, \blk,
is the most informative parent or reference of \blkfem
because it is the parent that exhibits the
least deviation relative
to \blkfem.
Here, the \blkfem visualization
is not really all that surprising given the \blk
visualization.
We refer to this phenomenon of being deceived by
a local difference or deviation relative to a deceptive
reference as an instance of the {\em drill-down fallacy}.
One way to avoid such fallacies is to ensure that one or more
informative parents
are present for each visualization so that analysts
can contextualize the visualization accurately.
While this fallacy is applicable to any
chart type that can be described as a
probability distribution over data
(e.g., pie charts, heatmaps),
we will limit our discussion to bar charts for brevity.}

% \subsection{Three Elements of Informative Exploration}
\change{\subsection{The ``3S'' Design Principles}}
Our goal is to help analysts discover
the key insights in a dataset while avoiding drill-down fallacies.
We \change{outline}
three essential principles for
finding such insights---the three S's:
\emph{safety}, \emph{saliency}, and \change{\emph{succinctness},
and progressively layer these principles to formalize
a measure of utility for a network of visualizations}.
We adopt these principles to
develop a visual exploration tool
that \change{automatically generates
a network of visualizations conveying the key
insights in a multidimensional dataset}.

\subsubsection{Safety}
\change{To prevent
drill-down fallacies,
we ensure {\em safety}---by making sure
that informative parents are present
to accurately contextualize visualizations.
A parent is said to be {\em informative}
if its data distribution closely follows the child
visualization's data distribution,
since the presence of the parent allows
the analyst to form an accurate mental model
of what to expect from the child visualization.
We compute the informativeness of
the $j^{th}$ parent $V_i^j$
for a visualization $V_i$
as the similarity between their data distributions
measured using a distance function $D$.
For bar charts, the data distribution refers to
the height of bars assigned to the categories labeled by the x-axis,
suitably normalized.
Accordingly, the computed distance
$D(V_i, V_i^j)$
refers to the sum of the distances
between the normalized heights of bars across different categories.
Quantifying deviation using distances between normalized versions of visualizations
in this manner is not a novel idea---we leverage prior work for this~\cite{Vartak2015,Siddiqui2017,Macke2018,Ding2016}.
The specific distance measure $D$ is not important; while we use the Euclidean metric,
we can easily work with other common distance metrics such as Kullback-Leibler Divergence and Earth Mover's distance~\cite{Vartak2015}.
The most informative parent $V_i^\dagger$ for a visualization $V_i$ is
the one whose data distribution is most similar to $V_i$.
}
%The distance $D(V_i, V_i^j)$ is computed based on the probability distributions represented by each visualization (in this case, a vector of bar values). \tr{For example, based on the Figure~\ref{fig:elections_example} example, the Euclidean distance between \fem ($V_i^j$=[54,41,5]) and \blkfem ($V_i$=[94,4,2]) is 54.57.} sqrt((94-54)**2+(41-4)**2+3**2)

\begin{equation}
    V_i^\dagger= \underset{V_i^j}{argmin}\ D(V_i, V_i^j)
\end{equation}
\change{Instead of insisting that the most informative
parent is always present to contextualize a given child visualization,
we relax our requirement somewhat: we don't need {\em the
most} informative parent to be present, just {\em an} informative parent.
We define a parent to be informative (denoted $V_i^*$) if its distance from the child falls within a threshold $\theta\%$ of the
most informative parent---the default is set to 90\%
and adjustable by the user.}
\tr{
    We regard a parent visualization as informative if its distance from the child visualization falls within a threshold $\theta\%$ compared to the most informative parent:
    \begin{equation}
        V_i^{*, \theta} = \{V_i^j : \frac{D(V_i, V_i^*)}{D(V_i, V_i^j)} \geq \theta\}
    \end{equation}
    For example in Figure~\ref{fig:elections_example}, while both \blk and \fem visualizations are considered parents of the \blkfem visualization, only the \blk visualization is considered an informative parent of the \blkfem population, for any values of $\theta \geq 11\%$ via the Euclidean distance metric.
}
\subsubsection{Saliency}
\change{Simply ensuring that
informative parents are present is insufficient;
we also want to emphasize {\em saliency} by
identifying visualizations that convey new information.
In general, a visualization is deemed to be \emph{interesting}
if its underlying data distribution differs
from that of its parents,
and thus offers new unexpected information or insight.
Such distance-based notions of interestingness
have been explored in past work~\cite{Correll2016,Itti2009,Vartak2015},
where a large distance from some reference visualization
indicates that the selected visualization is interesting.
We deviate from this prior work in two ways:
first, we concentrate on {\em informative} interestingness,
where the interestingness of a child visualization
is only defined with respect to informative parent references.
Second, we weigh the interestingness by the proportion of the
population captured by the child visualization.
(That is, when a deviation is manifested in a larger population,
it is deemed to be more significant and therefore more interesting.)
Thus, we define the utility of a visualization $V_i$, $U(V_i)$ as follows:
 $$
    U(V_i)=
\begin{cases}
     \frac{|V_i|}{|V_i^*|} \cdot D(V_i, V_i^*) & \text{if } V_i^* \text{ is present}\\
    -\infty             & \text{otherwise}
\end{cases}
$$
That is, the utility or interestingness of a visualization
is the distance between the visualization and its informative
parent, if present\footnote{If multiple informative parents, $V_i^*$, are present for a given visualization, $V_i$, then $U(V_i)$ is defined in terms of the most informative parent present.}. To incorporate the effect of subpopulation size into our objective function, we multiply the distance $D(V_i, V_i^*)$ between an informative parent $V_i^*$ and a child visualization $V_i$ by the ratio of their sizes.
Notice that the objective $U$ has a minimax form~\cite{wiki:minimax},
in that informativeness aims to minimize the distance between parent and child,
while interestingness aims to maximize the resulting minimum distance.
For convenience, we define $U(V_0)$, where $V_0$ is the overall visualization,
to be $1$, which is the maximum value that the expression $\frac{|V_i|}{|V_i^*|} \cdot D(V_i, V_i^*)$ can take, ensuring that the overall visualization
is always valuable to include.
}

\subsubsection{Succinctness}
\change{
We cannot possibly display all of the visualizations
in the lattice of data subsets: this lattice scales
exponentially in the number of attributes.
Instead, we aim for {\em succinctness},
where we only select a subset $S$ of size $|S| = k$ from all the visualizations.
We define the utility of $S$ as follows:
$$U(S) = \sum_{V_i \in S}{U(V_i)}$$
In this subset, for every visualization except for the overall
visualization, one of its informative
parents must be present (otherwise $U = -\infty$).
Thus, this subset ends up being a connected network
(a sub-graph of the overall lattice) rooted at the overall visualization,
ensuring that for each visualization, there is an informative parent available
for context.
We can now formally define our problem statement.
\par \textsc{Problem.} \textit{Given a dataset and user-provided X, Y attributes,
select a subset $S$ of $|S| = k$ visualizations from the lattice of data
subsets $\mathcal{L}$, such that $U(S)$ is maximized.}
\\
Thanks to how we have defined $U$, $S$ will include the overall visualization,
corresponding to the entire dataset with no filter. And,
for each visualization in $S$ except the overall one,
at least one of its informative parents will be present in $S$.
This network of visualizations $S$ can be displayed on a dashboard.
}
% To succinctly convey insights, we concentrate on \emph{summarization}---identifying a group of visualizations that collectively contain informative insights. Since our aim is to identify a unified narrative, instead of discrete insights, we enforce that any selected visualization must have at least one of its informative parents present in the dashboard. Specifically, we identify a set of $k$ connected visualizations that collectively maximize the sum of the proposed utility $U(V_i)$ across each selected visualization, $V_i$, and thus succinctly convey informative insights, more formally stated as follows:
% \par \textsc{Problem.} \textit{Given a dataset and user-provided X, Y attributes, select $k$ visualizations from the lattice of data subsets $\mathcal{L}$ to be included in the dashboard, such that:
% \\ (i) one of the selected visualization is the overall visualization, corresponding to the entire dataset with no filter;
% \\ (ii) for each visualization except for the overall, at least one of its informative parents is present in the $k$ visualizations;
% \\ (iii) the $k$ selected visualizations maximize the total utility $\sum_{V_i \in \mathcal{L}} U(V_i)$ as defined above.
% }
% and aggregation function G, a lattice $\mathcal{L}$ consisting of visualizations $V_i$ for all possible filter $F_i$ that could be constructed from dataset D:}
% \\ \texttt{$V_i$ = SELECT X, G(Y) FROM D WHERE $F_i$ GROUP BY X}
% \\ \textit{find k visualizations from $\mathcal{L}$ to include in dashboard $\mathcal{S}$, such that the total utility $\sum_{V_i \in \mathcal{L}} U(V_i)$ as defined above is maximized, while enforcing that all $V_i \in \mathcal{S}$ is connected.}
\change{Since the edges between non-informative parents to children are not
pertinent to the solution,
we can remove those edges from the lattice, leaving
only the edges from the informative parents to the children.
Then, we are left with an arbitrary graph,
from which we need to select a rooted subgraph of size $k$,
with greatest utility $U$.
For arbitrary distance metrics $D$,
this problem can be viewed to be {\sc NP-Hard} via a
reduction from the {\sc NP-Hard} problem of selecting items
with prerequisites~\cite{Parameswaran2010} (specifically, the AND graph variant).
\papertext{The proof can be found in our technical report~\cite{TR}.}
}
% Unfortunately, the problem of finding a
% connected subgraph in a lattice with
% maximum total edge utility is known
% as the \emph{maximum-weight connected subgraph problem}~\cite{ErnstAlthaus2009}
% and is known to be {\sc NP-Complete}~\cite{Parameswaran2010}.
% \agp{This doesn't actually show that our problem is hard. We need to reduce max-weighted subgraph to our problem, not the other way around. I am leaving a pointer here to think about it later.}
\change{Next, we design an approximate algorithm
 to solve this problem.}
