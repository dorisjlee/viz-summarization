%!TEX root = main.tex
\section{Introduction}

The journey of understanding a multi-dimensional dataset often begins with visualizations, exploring the space of attributes, in search of insights. Perhaps the most common route of this journey is to generate visualizations to gain an overview of the data, and drill-down to interesting subsets to generate more visualizations. For example, a campaign manager may be interested in understanding the voting patterns across different demographics (say, race, gender, social class) using the 2016 US election exit polls\footnote{https://edition.cnn.com/election/2016/results/exit-polls}. A natural first step is to generate a bar chart for the entire population, where x-axis shows the election candidates and y-axis the percentage of votes for these candidates. He then can drill down to specific demographics of interest, say gender based demographics by generating bar charts for female. %A further drill-down on race will lead to more specific demographics such as white male, and black female. 
\begin{figure}[h!]
\includegraphics[width=\linewidth]{figures/elections_example_lattice.pdf}
\caption{Example data subset lattice illustrating the misleading factor fallacy along the orange path as opposed to the informative purple path.}
\label{fig:elections_example}
\end{figure}
In this exploration process each drill-down may lead to insights, which derive from the observed visualizations. For example, the drill-down on gender shows that the female demographics follow the trend of overall population, whereas a further drill-down on race shows that the trend of black females differ from that of females. Many existing tools will flag the latter as a potential insight, since the black females exhibit a high deviation w.r.t. an observed parent. The insight, however, is a by-product of the order in which the drill-down has been performed---drilling down on race before gender will explain the trend of black females in light of black demographic. This example demonstrates the case of \emph{drill-down fallacy}, which results from potentially confounding factors/variables not explored in a drill-down path.

Exploring a dataset by selecting a random attribute at each drill-down step analysts become prone to the drill-down fallacy. A naive solution to avoid this fallacy is to explore all potential pathways along the drill-down path. For example, generating and exploring visualizations for both race and gender based demographics, before exploring any of their combinations. Unfortunately, this approach does not scale with increasing number of factors in the drill-down path.

In this paper we develop a tool to help users explore a dataset while avoiding the risk of drill-down fallacy. Our tool automatically identifies the best possible drill-down paths that leads to \emph{informative insights}, and summarizes the paths. The key idea of our tool is \emph{informativeness}---the capability of the observed visualizations to explain the unseen visualizations. Informativeness prevents users from the drill-down fallacy, and helps identify meaningful insights that arise from the irregularities in the data (instead of confounding variables).

Our user study results described in Section 5 shows that this notion of informativeness can guide an analyst towards meaningful insights. The contribution of this paper include:
\begin{denselist}
\item Introducing the novel concept of \emph{informativeness} that helps avoid drill-down fallacy in data exploration (Section 3),
\item Designing a tool that automatically identifies the best possible drill-down paths based on informative insights, and summarizes those (Section 4),
\item Demonstrating the efficacy of our system through a comprehensive user study evaluation (Section 5).
\end{denselist}

\iffalse

%\par Common analytics tasks, such as causal inference, feature selection, and outlier detection require studying data distributions at different levels of data granularity~\cite{Anand2015,Wu2013,Heer2012}. For example, a campaign manager may be interested in the voting patterns across different demographics (say, race, gender, social class) using the 2016 US election exit polls\footnote{\url{https://edition.cnn.com/election/2016/results/exit-polls}} to identify demographic groups for targeted advertisement. Visual analysis is the common approach for performing such analytics tasks, in which an analyst constructs visualizations to capture the distributions at different subsets of data. The goal of this visual analysis is to extract meaningful insights---when a set of visualizations along with human interpretation leads to informative and interesting facts about the underlying distributions.

%\par However, without knowing \textit{what} subset of data contains an insightful distribution, manually exploring distributions from all possible data subsets can be tedious and inefficient. For example, the aforementioned campaign manager could construct bar charts for all possible demographics, where x-axis shows the election candidates and y-axis the percentage of votes for these candidates. Subsequently, he may visually compare these bar charts to understand how voting pattern changes across different demographics. Even after constructing the visualizations for all possible data subsets, which itself is a daunting task, currently there is no systematic way for the campaign manager to make sense of or even navigate through this large space of possible visualizations to draw meaningful insights. %Both exercises, first, constructing the large number of visualizations corresponding to all possible data subsets, and then, navigating through this large space of visualizations to draw meaningful insights is challenging, particularly because there is no systematic way to perform these exercises.

%\par To this end, we present \system, an interactive visualization summarization system that automatically selects a small set of visualizations to summarize the distributions within a dataset in an informative manner. Our system is motivated by our observation that when an analyst is aware of the distributions present in different data subsets, she can draw meaningful insights and establish correlations about related visualizations that she has not yet seen with ease. We define this aspect of dataset understanding as \emph{distribution awareness}. For example, based on the vote distributions for different demographics shown in Figure~\ref{fig:elections_example}, an analyst can infer that most demographic groups have similar voting behaviors for `Clinton' and `Trump' (a,b,c,e,f), whereas black demographic groups are strongly skewed towards voting for `Clinton' (d,g,h). Since human analysts have limited time and memory, it is often impossible to explore visualizations from all data subsets. An ideal summarization system should display visualizations that enables the analyst to achieve \emph{maximal distribution awareness}, from which she can reasonably approximate most of the remaining unseen visualizations in a dataset.

%\par Nevertheless, finding effective visualizations to summarize a dataset is not as trivial as picking individual visualizations that maximizes some statistical measure, such as deviation~\cite{Vartak2015}, coverage~\cite{Sarvghad2017}, or significance testing~\cite{Anand2015}, which can often result in misleading summarizations. For example, if the campaign manager uses a deviation based metric to identify insightful distributions \cite{Vartak2015}, he could find that the voting pattern of black females is drastically different from the voting pattern of general female population. Accordingly, he might allocate his advertisement funds to target the black female population. While black females do defy the trends of general females, the comparison is incomplete, since it ignores the fact that black females very closely follows the voting pattern of the black population. Accordingly, the proper demographic to target should be the black population rather than the more specific black female population.

%Consider an elections campaign manager who is allocating the advertisement budget to be spent on different demographic populations to target for an upcoming election by investigating the voting patterns across different demographic groups. He performs a randomized permutation testing between the gender and race attributes and finds that the voting pattern of black females is drastically different from the voting pattern of general female population and allocates the his advertisement funds to target the black female population. While black females do defy the trends of general females, the comparison is incomplete, since it ignores the fact that black females follows very closely to the distribution of the voting behavior of the black population, so the proper subpopulation to target should be the black population rather than the more specific black female population.

%Even after constructing the visualizations for all possible data subsets, which itself is a daunting task, currently there is no systematic way for our campaign manager to make sense of or even navigate through this large space of possible visualizations to draw meaningful insights.

%\par The goal of visual analysis is to extract meaningful stories or insights from the data. Individual visualizations represent simple ``factoids'' portraying one aspect of the data. Meaningful insights arise when a group of factoids work in conjunction, along with human interpretation, to produce informative and interesting facts.
%\par However, without knowing \textit{what} subset of the data would be interesting to visualize, manual drill-downs and roll-ups on all possible filter combinations can be tedious and inefficient for analysts. In many data analytics scenarios, analysts have an x and y axis of interest and want to explore data subsets corresponding to different filtering criteria. For example, a campaign manager may be interested in looking at bar chart visualizations of x as the voted candidate and y as the percentage of votes for the 2016 US elections exit polls with different filter combinations on demographics information, such as gender, income, race, states, and responses to different survey questions\footnote{\url{https://edition.cnn.com/election/2016/results/exit-polls}}. The analyst would have to compare across a combinatorially large space of different data subsets by iteratively changing the filter criterion of a visualization to understand how the relationship between the x and y variables change across data subsets. Even if the analyst had plotted visualizations for all possible data subsets, currently there is no systematic and effective way for an analyst to make sense of and navigate through the large space of possible visualizations to draw meaningful insights.
%\par To this end, we present \system, an interactive visualization summarization system that automatically selects a small set of visualizations to summarize the data distributions within a dataset in an informative manner. When analysts inspect informative visualizations that cover these insights, they associate particular sets of attributes to typical trends and observed patterns. We define this aspect of dataset understanding as \emph{distribution awareness}. For example, we observe that in Figure~\ref{fig:elections_example}, most of the visualizations has `Clinton' and `Trump' as comparably-sized bars with `Others' being a small fraction of the overall (a,b,c,e,f), whereas visualizations involving the Black population is highly skewed towards `Clinton' (d,g,h). Since human analysts have limited memory and attention, it is often impossible to visualize all possible data subsets. An ideal summarization system should display visualizations that enables users to gain maximal distribution awareness of the typical trends within a dataset.
%\par However, finding effective visualizations to summarize a dataset is not as trivial as picking individual visualizations that maximizes some statistical measure, such as deviation~\cite{Vartak2015}, coverage~\cite{Sarvghad2017}, or significance testing~\cite{Anand2015}, which can often result in misleading summarizations. Consider an elections campaign manager who is allocating the advertisement budget to be spent on different demographic populations to target for an upcoming election by investigating the voting patterns across different demographic groups. He performs a randomized permutation testing between the gender and race attributes and finds that the voting pattern of black females is drastically different from the voting pattern of general female population and allocates the his advertisement funds to target the black female population. \dor{Himel, can you check if this example makes sense? or should we say chi2? chi2 just give you columnar correlation info not at the attribute-level info? although probably only a deviation based comparison can give you a comparison like this.} While black females do defy the trends of general females, the comparison is incomplete, since it ignores the fact that black females follows very closely to the distribution of the voting behavior of the black population, so the proper subpopulation to target should be the black population rather than the more specific black female population.

The above example demonstrates a scenario where the selection of an improper reference (female) for comparing the visualization (black female) against results in misleading insights. In \system, we formulate an objective where a visualization is \emph{actually} interesting when it deviates from and can not be explained by \emph{even} its most informative reference. %\dor{can we add an example here?}
Our user study results described in Section~\ref{sec:userstudy} shows that this notion of informative interestingness can guide an analyst towards more meaningful stories for further investigation. The contribution of this paper include:
\begin{denselist}
\item Proposing the novel problem of visualization summarization and use cases highlighting the importance of \textit{distribution awareness} in dataset understanding (Section~\ref{sec:distributionaware}), %inform  visualization understanding and analytical tool designs
\item Formulating the structure and utility of the visualization search space (\emph{lattice}) using a user expectation model motivated by our formative study (Section~\ref{sec:datamodel}),
\item Designing efficient algorithms and optimizations to identify a set of informatively connected interesting visualizations (Section~\ref{sec:system}),
\item Presenting an interactive visualization dashboard interface that adopts a simple and intuitive hierarchical lattice layout (Section~\ref{sec:interaction}),
\item Demonstrate the efficacy of our system through a user study evaluation (Section~\ref{sec:userstudy}).
\end{denselist}
\fi

%\hdev{Let's take a step back, and look at the current flow in introduction. In the first paragraph, we vaguely motivate what can be considered as collective insights. In second paragraph, we try to connect the idea of collective insights with the challenges of data subset exploration. In third paragraph, we introduce two concepts: visual summarization, and distribution awareness. We do not clearly state what these two means. There's an example that conveys what could be captured through pattern or trend mining. In the fourth paragraph, we present an example to convey some specific challenges of visual summarization. The fifth paragraph states our contributions. My suggestion is to immediately jump into business by saying what we mean by distribution awareness, why is it important, and why is this challenging. We have the contents lying around already, it's just a matter of clearly stating these three aspects, preferably without using new abstractions.}
