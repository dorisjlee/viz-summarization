@article{Kim2017,
abstract = {We present GraphScape, a directed graph model of the vi-sualization design space that supports automated reasoning about visualization similarity and sequencing. Graph nodes represent grammar-based chart specifications and edges rep-resent edits that transform one chart to another. We weight edges with an estimated cost of the difficulty of interpreting a target visualization given a source visualization. We con-tribute (1) a method for deriving transition costs via a partial ordering of edit operations and the solution of a resulting lin-ear program, and (2) a global weighting term that rewards consistency across transition subsequences. In a controlled experiment, subjects rated visualization sequences covering a taxonomy of common transition types. In all but one case, GraphScape's highest-ranked suggestion aligns with subjects' top-rated sequences. Finally, we demonstrate applications of GraphScape to automatically sequence visualization presen-tations, elaborate transition paths between visualizations, and recommend design alternatives (e.g., to improve scalability while minimizing design changes).},
author = {Kim, Younghoon and Wongsuphasawat, Kanit and Hullman, Jessica and Heer, Jeffrey},
doi = {10.1145/3025453.3025866},
file = {:Users/dorislee/Dropbox/Papers/Kim et al.{\_}2017{\_}GraphScape A Model for Automated Reasoning about Visualization Similarity and Sequencing.pdf:pdf},
isbn = {9781450346559},
journal = {Proc. of ACM CHI 2017},
keywords = {UI Author Keywords visualization,automated design,model,sequence,transition},
mendeley-groups = {HILDA,HILDA/CHI-data-papers,viz-rec/CHI},
title = {{GraphScape: A Model for Automated Reasoning about Visualization Similarity and Sequencing}},
year = {2017}
}
@article{Hullman2017,
author = {Hullman, Jessica and Kosara, Robert and Lam, Heidi},
file = {:Users/dorislee/Dropbox/Papers/Hullman, Kosara, Lam{\_}2017{\_}Finding a Clear Path Structuring Strategies for Visualization Sequences.pdf:pdf},
number = {3},
title = {{Finding a Clear Path : Structuring Strategies for Visualization Sequences}},
volume = {36},
year = {2017}
}

@article{ErnstAlthaus2009,
author = {Ernst Althaus and Markus Blumenstock and Disterhoft, Alexej and Andreas Hildebrandt and Markus Krupp},
doi = {10.1007/978-3-642-02026-1},
isbn = {978-3-642-02025-4},
issn = {0302-9743},
keywords = {bioinformatics,gene regulation,heuristics,k -cardinality tree,linear programming,tion},
mendeley-groups = {viz-rec},
pages = {313--321},
title = {{Algorithms for the Maximum Weight Connected k-Induced Subgraph Problem}},
url = {http://dl.acm.org/citation.cfm?id=1574064.1574101},
volume = {5573},
year = {2009}
}
@article{Ehsan2016,
abstract = {To support effective data exploration, there is a well-recognized need for solutions that can automatically rec-ommend interesting visualizations, which reveal useful insights into the analyzed data. However, such visualizations come at the expense of high data processing costs, where a large number of views are generated to evaluate their usefulness. Those costs are further escalated in the presence of numerical dimensional attributes, due to the potentially large number of possible binning aggregations, which lead to a drastic increase in the number of possible visualizations. To address that challenge, in this paper we propose the MuVE scheme for Multi-Objective View Recommendation for Visual Data Exploration. MuVE introduces a hybrid multi-objective utility function, which captures the impact of binning on the utility of visualizations. Consequently, novel algorithms are proposed for the efficient recommendation of data visualizations that are based on numerical dimensions. The main idea underlying MuVE is to incrementally and progressively assess the different benefits provided by a visualization, which allows an early pruning of a large number of unnecessary op-erations. Our extensive experimental results show the significant gains provided by our proposed scheme.},
author = {Ehsan, Humaira and Sharaf, Mohamed A and Chrysanthis, Panos K},
file = {:Users/dorislee/Box/Papers/0cdd343227a6c10104216fb86cbbdd9d8678.pdf:pdf},
journal = {2016 IEEE 32nd International Conference on Data Engineering, ICDE 2016},
mendeley-groups = {HILDA/Viz/System/VizRec},
title = {{MuVE: Efficient Multi-Objective View Recommendation for Visual Data Exploration}},
year = {2016}
}

@article{Geng,
abstract = {See, stats, and : https : / / www . researchgate . net / publication / 220566216 Interestingness : A survey Article Impact : 3 . 37 : 10 . 1145 / 1132960 . 1132963 : DBLP CITATIONS 541 READS 1 , 080 2 , including : Howard . Hamilton University 176 , 957 SEE All - text , letting . Available : Howard . Hamilton Retrieved : 10 Interestingness measures play an important role in data mining , regardless of the kind of patterns being mined . These measures are intended for selecting and ranking patterns according to their potential interest to the user . Good measures also allow the time and space costs of the mining process to be reduced . This survey reviews the interestingness measures for rules and summaries , classifies them from several perspectives , compares their properties , identifies their roles in the data mining process , gives strategies for selecting appropriate measures for applications , and identifies opportunities for future research in this area .},
author = {Geng, Liqiang and Hamilton, Howard J},
doi = {10.1145/1132960.1132963},
file = {:Users/dorislee/Dropbox/Papers/Geng, Hamilton{\_}Unknown{\_}Interestingness Measures for Data Mining A Survey.pdf:pdf},
keywords = {Algorithms,Categories and Subject Descriptors,Database Applications—Data mining General Terms,H 2 8 [ Database Management ],Knowledge discovery,Measurement Additional Key Words and Phrases,association rules,classification rules,interest measures,interestingness measures,summaries},
title = {{Interestingness Measures for Data Mining : A Survey}}
}
@article{Freitas,
abstract = {Most of the literature argues that surprisingness is an inherently subjective aspect of the discovered knowledge, which cannot be measured in objective terms. This paper departs from this view, and it has a twofold goal: (1) showing that it is indeed possible to define objective (rather than subjective) measures of discovered rule surprisingness; (2) proposing new ideas and methods for defining objective rule surprisingness measures.},
author = {Freitas, Alex A},
file = {::},
title = {{On Objective Measures of Rule Surprisingness}},
url = {http://www.dainf.cefetpr.br/{~}alex}
}
@article{Silberschatz,
abstract = {One of the central problems in the field of knowledge discovery is the development of good measures of in-terestingness of discovered patterns. Such measures of interestingness are divided into objective measures -those that depend only on the structure of a pat-tern and the underlying data used in the discovery process, and the subjective measures -those that also depend on the class of users who examine the pattern. The purpose of this paper is to lay the groundwork for a comprehensive study of subjective measures of interestingness. In the paper, we clas-sify these measures into actionable and unexpected, and examine the relationship between them. The unexpected measure of interestingness is defined in terms of the belief system that the user has. Inter-estingness of a pattern is expressed in terms of how it affects the belief system.},
author = {Silberschatz, Avi},
file = {:Users/dorislee/Dropbox/Papers/Silberschatz{\_}Unknown{\_}On Subjective Measures of Interestingness in Knowledge Discovery.pdf:pdf},
title = {{On Subjective Measures of Interestingness in Knowledge Discovery}}
}
@article{Mcgarry2005,
abstract = {It is a well known fact that the data mining process can generate many hundreds and often thousands of patterns from data. The task for the data miner then becomes one of determining the most useful patterns from those that are trivial or are already well known to the organization. It is therefore necessary to filter out those patterns through the use of some measure of the patterns actual worth. This article presents a review of the available literature on the various measures devised for evaluating and ranking the discovered patterns produced by the data mining process. These so called interestingness measures are generally divided into two categories: objective measures based on the statistical strengths or properties of the discovered patterns and subjective measures which are derived from the user's beliefs or expectations of their particular problem domain. We evaluate the strengths and weaknesses of the various interestingness measures with respect to the level of user integration within the discovery process.},
author = {Mcgarry, Ken},
doi = {10.1017/S000000000000000},
file = {::},
journal = {The Knowledge Engineering Review},
pages = {1--24},
publisher = {Cambridge University Press},
title = {{A Survey of Interestingness Measures for Knowledge Discovery}},
volume = {000},
year = {2005}
}
@article{Sarawagi2000,
abstract = {In this paper we present a tool for enhanced exploration of OLAP data that is adaptive to a user's prior knowledge of the data. The tool continuously keeps track of the parts of the cube that a user has visited. The information in these scattered visited parts of the cube is pieced together to form a model of the user's expected values in the unvisited parts. The mathematical foundation for this modeling is provided by the classical Maximum Entropy principle. At any time, the user can query for ...},
author = {Sarawagi, S.},
file = {:Users/dorislee/Dropbox/Papers/Sarawagi{\_}2000{\_}User-adaptive exploration of multidimensional data.pdf:pdf},
isbn = {1558607153},
journal = {Proc of the 26th Intl Conference on Very Large},
pages = {307--316},
title = {{User-adaptive exploration of multidimensional data}},
url = {http://citeseer.ist.psu.edu/sarawagi00useradaptive.html},
year = {2000}
}
@article{Sarawagi1998,
author = {Sarawagi, S and Agrawal, R and Megiddo, N and {Univ Politecn Valencia}, Generalitat Valenciana Ajuntament Valencia and {Edbt Fdn}, E T H Zurich Oracle Sybase Softlab Iberia},
file = {:Users/dorislee/Dropbox/Papers/Sarawagi et al.{\_}1998{\_}Discovery-driven exploration of OLAP data cubes.pdf:pdf},
isbn = {3-540-64264-1},
issn = {03029743},
journal = {6th International Conference on Extending Database Technology (EDBT 98)},
pages = {168--182},
title = {{Discovery-driven exploration of OLAP data cubes}},
year = {1998}
}
@article{Anand2015,
author = {Anand, Anushka and Talbot, Justin},
doi = {10.1109/TVCG.2015.2467323},
file = {:Users/dorislee/Dropbox/Papers/Anand, Talbot{\_}2015{\_}Automatic Selection of Partitioning Variables for Small Multiple Displays.pdf:pdf},
number = {c},
title = {{Automatic Selection of Partitioning Variables for Small Multiple Displays}},
volume = {2626},
year = {2015}
}
@article{Vartak2015,
author = {Vartak, Manasi and Rahman, Sajjadur and Madden, Samuel and Parameswaran, Aditya and Polyzotis, Neoklis},
year={2015},
title = {{SEEDB : Efficient Data-Driven Visualization Recommendations to Support Visual Analytics}}
}

@article{Wongsuphasawat2016,
abstract = {General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.},
author = {Wongsuphasawat, Kanit and Moritz, Dominik and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
doi = {10.1109/TVCG.2015.2467191},
file = {:Users/dorislee/Dropbox/Papers/Wongsuphasawat et al.{\_}2016{\_}Voyager Exploratory Analysis via Faceted Browsing of Visualization Recommendations.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Browsers,Compass,Data visualization,Encoding,Grammar,Image color analysis,Visualization},
mendeley-groups = {HILDA/Viz/System/VizRec},
number = {1},
pages = {649--658},
title = {{Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations}},
volume = {22},
year = {2016}
}
@article{Sarawagi1999,
abstract = {Our goal is to enhance multidimensional database systems with advanced mining prim- itives. Current Online Analytical Processing (OLAP) products provide a minimal set of basic aggregate operators like sum and aver- age and a set of basic navigational operators like drill-downs and roll-ups. These operators have to be driven entirely by the analyst's in- tuition. Such ad hoc exploration gets tedious and error-prone as data dimensionality and size increases. In earlier work we presented one such advanced primitive where we pre- mined OLAP data for exceptions, summarized the exceptions at appropriate levels, and used them to lead the analyst to the interesting re- gions. In this paper we present a second enhance- ment: a single operator that lets the ana- lyst get summarized reasons for drops or in- creases observed at an aggregated level. This eliminates the need to manually drill-down for such reasons. We develop an information the- oretic formulation for expressing the reasons that is compact and easy to interpret. We de- sign a dynamic programming algorithm that requires only one pass of the data improv- ing significantly over our initial greedy algo- rithm that required multiple passes. In ad- dition, the algorithm uses a small amount of Part of the work was done when the author was at IBM ∗ Almaden Research Center, USA Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 25th VLDB Conference, Edinburgh, Scotland, 1999. memory independent of the data size. This allows easy integration with existing OLAP products. We illustrate with our prototype on the DB2/UDB ROLAP product with the Excel Pivot-table frontend. Experiments on this prototype using the OLAP data bench- mark demonstrate (1) scalability of our algo- rithm as the size and dimensionality of the cube increases and (2) feasibility of getting in- teractive answers even with modest hardware resources. 1},
author = {Sarawagi, Sunita},
file = {:Users/dorislee/Dropbox/Papers/Sarawagi{\_}1999{\_}Explaining differences in multidimensional aggregates.pdf:pdf},
isbn = {1-55860-615-7},
journal = {Vldb},
pages = {42--53},
title = {{Explaining differences in multidimensional aggregates}},
year = {1999}
}

@article{Wu2017,
author = {Wu, Yifan and Xu, Larry and Chang, Remco and Wu, Eugene},
file = {:Users/dorislee/Box/Papers/bayesianvis-decisive17.pdf:pdf},
journal = {Dealing with Cognitive Biases in Visualizations (DECISIVe): a VIS 2017 workshop},
title = {{Towards a Bayesian Model of Data Visualization Cognition}},
year = {2017}
}
@misc{anand, 
url = {https://public.tableau.com/profile/anand4683#!/vizhome/InsightsfromKagglesTitanicdataset/Story1},
journal = {Tableau Public}, 
author = {Anand}
}
@article{Alipourfard2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1801.04385v1},
author = {Alipourfard, Nazanin and Fennell, Peter G. and Lerman, Kristina},
doi = {10.1145/3159652.3159684},
eprint = {arXiv:1801.04385v1},
file = {:Users/dorislee/Box/Papers/1801.04385.pdf:pdf},
isbn = {9781450355810},
journal = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining  - WSDM '18},
keywords = {both genders,ects analysis of trends,lower admissions rates for,s paradox,s paradox also a,simpson,trend analysis,when mea-},
pages = {19--27},
title = {{Can you Trust the Trend?}},
url = {http://dl.acm.org/citation.cfm?doid=3159652.3159684},
year = {2018}
}

@article{Guo2017,
author = {Guo, Yue and Binnig, Carsten and Kraska, Tim and Darmstadt, T U},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Guo et al. - 2017 - What you see is not what you get ! Detecting Simpson ' s Paradoxes during Data Exploration.pdf:pdf},
isbn = {9781450350297},
journal = {HILDA 2017 - Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
mendeley-groups = {viz-rec/CHI,viz-rec},
title = {{What you see is not what you get ! Detecting Simpson ' s Paradoxes during Data Exploration}},
year = {2017}
}

@article{Segel2010,
abstract = {Data visualization is regularly promoted for its ability to reveal stories within data, yet these {\&}{\#}8220;data stories{\&}{\#}8221; differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Segel, Edward and Heer, Jeffrey},
doi = {10.1109/TVCG.2010.179},
eprint = {arXiv:1011.1669v3},
file = {:Users/dorislee/Box/Papers/2010-Narrative-InfoVis.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Narrative visualization,case study,design methods,journalism,social data analysis,storytelling},
number = {6},
pages = {1139--1148},
pmid = {20975152},
title = {{Narrative visualization: Telling stories with data}},
volume = {16},
year = {2010}
}

@article{Boy2015,
author = {Boy, Jeremy and Detinenne, Francoise and Fekete, Jean-Daniel},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Paristech - 2015 - Storytelling in Information Visualizations Does it Engage Users to Explore Data.pdf:pdf},
isbn = {9781450331456},
journal = {CHI 2015},
mendeley-groups = {HILDA/Viz/Theory/Reviews},
pages = {1449--1458},
title = {{Storytelling in Information Visualizations : Does it Engage Users to Explore Data ?}},
year = {2015}
}

@article{Hullman2013,
abstract = {Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.},
author = {Hullman, Jessica and Drucker, Steven and {Henry Riche}, Nathalie and Lee, Bongshin and Fisher, Danyel and Adar, Eytan},
doi = {10.1109/TVCG.2013.119},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Hullman et al. - 2013 - A deeper understanding of sequence in narrative visualization.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data storytelling,narrative structure,narrative visualization},
mendeley-groups = {viz-rec/CHI},
number = {12},
pages = {2406--2415},
pmid = {24051807},
title = {{A deeper understanding of sequence in narrative visualization}},
volume = {19},
year = {2013}
}

@article{Hoque2017,
abstract = {Interactive visual data analysis is most productive when users can focus on answering the questions they have about their data, rather than focusing on how to operate the interface to the analysis tool. One viable approach to engaging users in interactive conversations with their data is a natural language interface to visualizations. These interfaces have the potential to be both more expressive and more accessible than other interaction paradigms. We explore how principles from language pragmatics can be applied to the flow of visual analytical conversations, using natural language as an input modality. We evaluate the effectiveness of pragmatics support in our system Evizeon, and present design considerations for conversation interfaces to visual analytics tools.},
author = {Hoque, Enamul and Setlur, Vidya and Tory, Melanie and Dykeman, Isaac},
doi = {10.1109/TVCG.2017.2744684},
file = {:Users/dorislee/Box/Papers/VAST2017{\_}105.pdf:pdf},
isbn = {1077-2626 VO  - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Coherence,Data visualization,Natural languages,Pragmatics,Tools,Visual analytics,ambiguity,feedback,interaction,language pragmatics,natural language,visual analytics},
number = {c},
title = {{Applying Pragmatics Principles for Interaction with Visual Analytics}},
year = {2017}
}

@misc{mushroom,
author = "Schlimmer, Jeff",
year = "1987",
title = "Mushroom Data Set. {UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@misc{autism,
author = "Fayez Thabtah, Fadi",
year = "2017",
title = "Autism Screening Adult Data Set. {UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences"}

@misc{titanic,
title = "Titanic: Machine Learning from Disaster",
url = "https://www.kaggle.com/c/Titanic",
institution = "Kaggle" }

@misc{police,
author = "Pierson, E. and Simoiu, C. and Overgoor, J. and Corbett-Davies, S. and  Ramachandran, V. and Phillips, C. and Goel, S.",
year = "2017",
title = "A large-scale analysis of racial disparities in police stops across the United States",
url = "https://openpolicing.stanford.edu/data/",
institution = "The Stanford Open Policing Project"}

@article{levene2003snowflake,
  title={Why is the snowflake schema a good data warehouse design?},
  author={Levene, Mark and Loizou, George},
  journal={Information Systems},
  volume={28},
  number={3},
  pages={225--240},
  year={2003},
  publisher={Elsevier}
}
@article{Binnig2017,
abstract = {Have you ever been in a sauna? If yes, according to our recent survey conducted on Amazon Mechanical Turk, people who go to saunas are more likely to know that Mike Stonebraker is not a character in “The Simpsons”. While this result clearly makes no sense, recently proposed tools to automatically suggest visualizations, correlations, or perform visual data exploration, significantly increase the chance that a user makes a false discovery like this one. In this paper, we first show how current tools mislead users to consider random fluctuations as significant discoveries. We then describe our vision and early results for QUDE, a new system for automatically controlling the various risk factors during the data exploration process.},
author = {Binnig, Carsten and Stefani, Lorenzo De},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Binnig, Stefani - 2017 - Towards Sustainable Insights or why polygamy is bad for you.pdf:pdf},
journal = {Cidr},
mendeley-groups = {viz-rec/CHI,viz-rec},
title = {{Towards Sustainable Insights or why polygamy is bad for you}},
year = {2017}
}
@article{Xin2007,
abstract = {Data cube computation is one of the most es-sential but expensive operations in data ware-housing. Previous studies have developed two major approaches, top-down vs. bottom-up. The former, represented by the Multi-Way Array Cube (called MultiWay) algorithm [25], aggregates simultaneously on multiple dimensions; however, it cannot take advan-tage of Apriori pruning [2] when computing iceberg cubes (cubes that contain only ag-gregate cells whose measure value satisfies a threshold, called iceberg condition). The latter, represented by two algorithms: BUC [6] and H-Cubing[11], computes the iceberg cube bottom-up and facilitates Apriori prun-ing. BUC explores fast sorting and partition-ing techniques; whereas H-Cubing explores a data structure, H-Tree, for shared computa-tion. However, none of them fully explores multi-dimensional simultaneous aggregation. In this paper, we present a new method, Star-Cubing, that integrates the strengths of the previous three algorithms and performs ag-gregations on multiple dimensions simultane-ously. It utilizes a star-tree structure, ex-tends the simultaneous aggregation methods, and enables the pruning of the group-by's that do not satisfy the iceberg condition. Our performance study shows that Star-Cubing is highly efficient and outperforms all the previ-ous methods in almost all kinds of data distri-butions.},
author = {Xin, Dong and Han, Jiawei and Li, Xiaolei and Shao, Zheng and Wah, Benjamin W.},
doi = {10.1109/TKDE.2007.250589},
file = {:Users/dorislee/Box/Papers/S15P02.pdf:pdf},
isbn = {0-12-722442-4},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Data mining,Data warehouse,Online analytical processing (OLAP)},
number = {1},
pages = {111--126},
title = {{Computing iceberg cubes by top-down and bottom-up integration: The starcubing approach}},
volume = {19},
year = {2007}
}

@article{Parameswaran2010,
abstract = {We consider the problem of recommending the best set of k items when there is an inherent ordering between items, expressed as a set of prerequisites (e.g., the movie ‘Godfather I' is a prerequi- site of ‘Godfather II'). Since this general problem is computation- ally intractable, we develop 3 approximation algorithms to solve this problem for various prerequisite structures (e.g., chain graphs, AND graphs, AND-OR graphs). We derive worst-case bounds for these algorithms for these structures, and experimentally evaluate these algorithms on synthetic data. We also develop an algorithm to combine solutions in order to generate even better solutions, and compare the performance of this algorithm with the other three.},
author = {Parameswaran, Aditya G. and Garcia-Molina, Hector and Ullman, Jeffrey D.},
doi = {10.1145/1871437.1871555},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Parameswaran, Garcia-Molina, Ullman - 2010 - Evaluating, combining and generalizing recommendations with prerequisites.pdf:pdf},
isbn = {9781450300995},
journal = {Proceedings of the 19th ACM international conference on Information and knowledge management - CIKM '10},
keywords = {graph theory,prerequisites,recommendation algorithms},
mendeley-groups = {viz-rec},
pages = {919},
title = {{Evaluating, combining and generalizing recommendations with prerequisites}},
url = {http://dl.acm.org/citation.cfm?id=1871555{\%}5Cnhttp://portal.acm.org/citation.cfm?doid=1871437.1871555},
year = {2010}
}
